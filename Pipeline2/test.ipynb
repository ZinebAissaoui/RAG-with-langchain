{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zaiss\\OneDrive - Ecole Centrale Casablanca\\Hackathon\\langchain\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from query import query_chroma_with_gemini\n",
    "from create_langchain_database_chroma import process_articles, load_data\n",
    "from langchain_community.embeddings.sentence_transformer import (\n",
    "    SentenceTransformerEmbeddings,\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.embeddings.sentence_transformer import (\n",
    "    SentenceTransformerEmbeddings,\n",
    ")\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import ArxivLoader\n",
    "import pandas as pd \n",
    "import google.generativeai as genai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = ArxivLoader(query='2402.07878', load_max_docs=2)\n",
    "documents = loader.load()\n",
    "if documents:\n",
    "        # split it into chunks\n",
    "        text_splitter = CharacterTextSplitter(separator='\\n', chunk_size=1000, chunk_overlap=0)\n",
    "        chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "        # save to disk\n",
    "        db = Chroma.from_documents(chunks, embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on this content: of the fold-trained model. In particular, we look at the\n",
      "F1 score standard deviation, which provides an insight\n",
      "into the consistency of the modelâ€™s performance and its\n",
      "ability to generalise to unseen data. A lower standard\n",
      "deviation indicates a more stable and reliable model,\n",
      "which corresponds to our case as shown in Table III.\n",
      "5) Model training: we perform training on the whole train-\n",
      "ing set. The resulting model is then used for performing\n",
      "tests on the test data set. The classification performance,\n",
      "so obtained, is reported in Table III.\n",
      "The above process has been repeated for each combination\n",
      "of the following two parameter sets:\n",
      "â€¢ Ï‰ parameter set: {Ï‰w, Ï‰w, Ï‰m}.\n",
      "â€¢ Ïƒ parameter set: {Ïƒ1, Ïƒ5, ÏƒN}.\n",
      "V. RESULTS AND DISCUSSION\n",
      "The approach and techniques described in the previous\n",
      "sections have been validated through numerical simulations. In\n",
      "order to ensure maximum reproducibility of our experiments,\n",
      "the source code used to perform the simulations has been made\n",
      "\n",
      "---\n",
      "\n",
      "of the fold-trained model. In particular, we look at the\n",
      "F1 score standard deviation, which provides an insight\n",
      "into the consistency of the modelâ€™s performance and its\n",
      "ability to generalise to unseen data. A lower standard\n",
      "deviation indicates a more stable and reliable model,\n",
      "which corresponds to our case as shown in Table III.\n",
      "5) Model training: we perform training on the whole train-\n",
      "ing set. The resulting model is then used for performing\n",
      "tests on the test data set. The classification performance,\n",
      "so obtained, is reported in Table III.\n",
      "The above process has been repeated for each combination\n",
      "of the following two parameter sets:\n",
      "â€¢ Ï‰ parameter set: {Ï‰w, Ï‰w, Ï‰m}.\n",
      "â€¢ Ïƒ parameter set: {Ïƒ1, Ïƒ5, ÏƒN}.\n",
      "V. RESULTS AND DISCUSSION\n",
      "The approach and techniques described in the previous\n",
      "sections have been validated through numerical simulations. In\n",
      "order to ensure maximum reproducibility of our experiments,\n",
      "the source code used to perform the simulations has been made\n",
      "\n",
      "---\n",
      "\n",
      "tion (FFS) with a SVM-RBF estimator to find a space\n",
      "in which data is successfully separable. A maximum\n",
      "of eight features has been chosen as an upper bound.\n",
      "Selections are not pursued if F1 score saturation is\n",
      "TABLE III\n",
      "FEATURE SELECTION, HYPERPARAMETERS TUNING, MODEL ROBUSTNESS AND MODEL PERFORMANCE RESULTS\n",
      "Ï‰u\n",
      "Ï‰w\n",
      "Ï‰m\n",
      "Ïƒ1\n",
      "Ïƒ5\n",
      "ÏƒN\n",
      "Ïƒ1\n",
      "Ïƒ5\n",
      "ÏƒN\n",
      "Ïƒ1\n",
      "Ïƒ5\n",
      "ÏƒN\n",
      "Feature selection\n",
      "F1\n",
      "0.9999\n",
      "0.9999\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0.9999\n",
      "0.9999\n",
      "1\n",
      "# features\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "Most significant feature\n",
      "CC\n",
      "CC\n",
      "CC\n",
      "CC\n",
      "CC\n",
      "DC\n",
      "CC\n",
      "CC\n",
      "DC\n",
      "Hyperparameters Tuning\n",
      "F1 score before tuning\n",
      "0.9999\n",
      "0.9999\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0.9999\n",
      "0.9999\n",
      "1\n",
      "F1 score after tuning\n",
      "0.9999\n",
      "0.9999\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0.9999\n",
      "0.9996\n",
      "1\n",
      "Percentage increment\n",
      "0.00%\n",
      "0.00%\n",
      "0.00%\n",
      "0.00%\n",
      "0.00%\n",
      "0.00%\n",
      "0.00%\n",
      "-0.3%\n",
      "0.00%\n",
      "Chosen Î³\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0,1\n",
      "1\n",
      "1\n",
      "0,1\n",
      "Chosen C\n",
      "102\n",
      "102\n",
      "10\n",
      "1\n",
      "1\n",
      "1\n",
      "102\n",
      "102\n",
      "1\n",
      "Model robustness\n",
      "F1 avg\n",
      "0.9999\n",
      "0.9999\n",
      "1\n",
      "0.9999\n",
      "0.9999\n",
      "1\n",
      "0.9999\n",
      "0.9999\n",
      "1\n",
      "F1 dev. std\n",
      "0.0001\n",
      "0.0001\n",
      "0\n",
      "0.0001\n",
      "0.0001\n",
      "0\n",
      "0.0001\n",
      "0.0001\n",
      "0\n",
      "Support vectors\n",
      "9\n",
      "9\n",
      "27\n",
      "93\n",
      "94\n",
      "282\n",
      "9\n",
      "9\n",
      "282\n",
      "Model performance on test data set\n",
      "F1 weighted avg\n",
      "\n",
      "---\n",
      "\n",
      "tion (FFS) with a SVM-RBF estimator to find a space\n",
      "in which data is successfully separable. A maximum\n",
      "of eight features has been chosen as an upper bound.\n",
      "Selections are not pursued if F1 score saturation is\n",
      "TABLE III\n",
      "FEATURE SELECTION, HYPERPARAMETERS TUNING, MODEL ROBUSTNESS AND MODEL PERFORMANCE RESULTS\n",
      "Ï‰u\n",
      "Ï‰w\n",
      "Ï‰m\n",
      "Ïƒ1\n",
      "Ïƒ5\n",
      "ÏƒN\n",
      "Ïƒ1\n",
      "Ïƒ5\n",
      "ÏƒN\n",
      "Ïƒ1\n",
      "Ïƒ5\n",
      "ÏƒN\n",
      "Feature selection\n",
      "F1\n",
      "0.9999\n",
      "0.9999\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0.9999\n",
      "0.9999\n",
      "1\n",
      "# features\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "Most significant feature\n",
      "CC\n",
      "CC\n",
      "CC\n",
      "CC\n",
      "CC\n",
      "DC\n",
      "CC\n",
      "CC\n",
      "DC\n",
      "Hyperparameters Tuning\n",
      "F1 score before tuning\n",
      "0.9999\n",
      "0.9999\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0.9999\n",
      "0.9999\n",
      "1\n",
      "F1 score after tuning\n",
      "0.9999\n",
      "0.9999\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0.9999\n",
      "0.9996\n",
      "1\n",
      "Percentage increment\n",
      "0.00%\n",
      "0.00%\n",
      "0.00%\n",
      "0.00%\n",
      "0.00%\n",
      "0.00%\n",
      "0.00%\n",
      "-0.3%\n",
      "0.00%\n",
      "Chosen Î³\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0,1\n",
      "1\n",
      "1\n",
      "0,1\n",
      "Chosen C\n",
      "102\n",
      "102\n",
      "10\n",
      "1\n",
      "1\n",
      "1\n",
      "102\n",
      "102\n",
      "1\n",
      "Model robustness\n",
      "F1 avg\n",
      "0.9999\n",
      "0.9999\n",
      "1\n",
      "0.9999\n",
      "0.9999\n",
      "1\n",
      "0.9999\n",
      "0.9999\n",
      "1\n",
      "F1 dev. std\n",
      "0.0001\n",
      "0.0001\n",
      "0\n",
      "0.0001\n",
      "0.0001\n",
      "0\n",
      "0.0001\n",
      "0.0001\n",
      "0\n",
      "Support vectors\n",
      "9\n",
      "9\n",
      "27\n",
      "93\n",
      "94\n",
      "282\n",
      "9\n",
      "9\n",
      "282\n",
      "Model performance on test data set\n",
      "F1 weighted avg\n",
      "\n",
      "---\n",
      "\n",
      "value is chosen, except for the weighted and mixed cases\n",
      "with Ïƒ = N. For the hyperparameter C, small values are\n",
      "always chosen (C â‰¤ 102). Such results show that the training\n",
      "instances are already well separated and do not require a\n",
      "complex hyperplane definition. In particular in the weighted\n",
      "and mixed cases cases with Ïƒ = N, the minimum value is\n",
      "chosen for both hyperparameters.\n",
      "3) Model robustness: We observe that the average F1 score\n",
      "is never smaller than 0.9999 and that the standard deviation is\n",
      "never greater than 0.0001, regardless of the values of Ïƒ and Ï‰,\n",
      "demonstrating good robustness of the model performance. For\n",
      "4https://github.com/secomms/GiBIDS\n",
      "TABLE IV\n",
      "COMPARISON WITH THE STATE OF THE ART\n",
      "IDS Model\n",
      "% train-test\n",
      "# ftrs\n",
      "F1\n",
      "FPR\n",
      "Sharafaldin et al. [5]\n",
      "N.A.\n",
      "49\n",
      "0.98\n",
      "N.A.\n",
      "Abdulhammed et al. [1]\n",
      "70-30\n",
      "10\n",
      "0.997\n",
      "0.1%\n",
      "Rodriguez et al. [3]\n",
      "50-50\n",
      "6\n",
      "0.990\n",
      "N.A.\n",
      "Thockchom et al. [2]\n",
      "80-20\n",
      "13\n",
      "0.9963\n",
      "0.43%\n",
      "Our approach {Ïƒ5, Ï‰u}\n",
      "0.98-65.53\n",
      "2\n",
      "0.9988\n",
      "0.02%\n",
      "Our approach {ÏƒN, Ï‰m}\n",
      "0.98-65.53\n",
      "2\n",
      "0.9988\n",
      "\n",
      "---\n",
      "\n",
      "value is chosen, except for the weighted and mixed cases\n",
      "with Ïƒ = N. For the hyperparameter C, small values are\n",
      "always chosen (C â‰¤ 102). Such results show that the training\n",
      "instances are already well separated and do not require a\n",
      "complex hyperplane definition. In particular in the weighted\n",
      "and mixed cases cases with Ïƒ = N, the minimum value is\n",
      "chosen for both hyperparameters.\n",
      "3) Model robustness: We observe that the average F1 score\n",
      "is never smaller than 0.9999 and that the standard deviation is\n",
      "never greater than 0.0001, regardless of the values of Ïƒ and Ï‰,\n",
      "demonstrating good robustness of the model performance. For\n",
      "4https://github.com/secomms/GiBIDS\n",
      "TABLE IV\n",
      "COMPARISON WITH THE STATE OF THE ART\n",
      "IDS Model\n",
      "% train-test\n",
      "# ftrs\n",
      "F1\n",
      "FPR\n",
      "Sharafaldin et al. [5]\n",
      "N.A.\n",
      "49\n",
      "0.98\n",
      "N.A.\n",
      "Abdulhammed et al. [1]\n",
      "70-30\n",
      "10\n",
      "0.997\n",
      "0.1%\n",
      "Rodriguez et al. [3]\n",
      "50-50\n",
      "6\n",
      "0.990\n",
      "N.A.\n",
      "Thockchom et al. [2]\n",
      "80-20\n",
      "13\n",
      "0.9963\n",
      "0.43%\n",
      "Our approach {Ïƒ5, Ï‰u}\n",
      "0.98-65.53\n",
      "2\n",
      "0.9988\n",
      "0.02%\n",
      "Our approach {ÏƒN, Ï‰m}\n",
      "0.98-65.53\n",
      "2\n",
      "0.9988\n",
      "\n",
      "---\n",
      "\n",
      "0.9988\n",
      "0.9988\n",
      "0.9987\n",
      "0.6016\n",
      "0.60\n",
      "0.9988\n",
      "0.9988\n",
      "0.9988\n",
      "0.9988\n",
      "Negatives/Benign\n",
      "Errors (False Positives)\n",
      "283\n",
      "272\n",
      "439\n",
      "1635\n",
      "1642\n",
      "133\n",
      "283\n",
      "272\n",
      "133\n",
      "F1\n",
      "0.9991\n",
      "0.9991\n",
      "0.9991\n",
      "0.8311\n",
      "0.8306\n",
      "0.9992\n",
      "0.9991\n",
      "0.9991\n",
      "0.9992\n",
      "FPR\n",
      "0.0002\n",
      "0.0002\n",
      "0.0003\n",
      "0.0012\n",
      "0.0012\n",
      "0.0001\n",
      "0.0002\n",
      "0.0002\n",
      "0.0001\n",
      "Positives/Attacks\n",
      "Errors (False Negatives)\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "530382\n",
      "532505\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "F1\n",
      "0.9979\n",
      "0.9979\n",
      "0.9977\n",
      "0.0480\n",
      "0.0406\n",
      "0.9980\n",
      "0.9979\n",
      "0.9979\n",
      "0.9980\n",
      "FNR\n",
      "0.0037\n",
      "0.0037\n",
      "0.0037\n",
      "0.9753\n",
      "0.9792\n",
      "0.0037\n",
      "0.0037\n",
      "0.0037\n",
      "0.0037\n",
      "reached. The results were validated through a 5-fold\n",
      "cross-validation.\n",
      "3) Hyperparameters tuning: the SVM-RBF requires tuning\n",
      "of the hyperparameters Î³ and C, which must be chosen\n",
      "accurately. We optimized them through a 5-fold cross-\n",
      "validated grid search with\n",
      "â€¢ C = {0.1, 1, 5, 10, 102, 103, 104, 105}\n",
      "â€¢ Î³ = {0.01, 0.1, 0.5, 1}\n",
      "4) Model robustness: once the best model configuration\n",
      "has been found, 10-fold cross-validation has been used\n",
      "for calculating, for each fold, the performance metrics\n",
      "\n",
      "---\n",
      "\n",
      "0.9988\n",
      "0.9988\n",
      "0.9987\n",
      "0.6016\n",
      "0.60\n",
      "0.9988\n",
      "0.9988\n",
      "0.9988\n",
      "0.9988\n",
      "Negatives/Benign\n",
      "Errors (False Positives)\n",
      "283\n",
      "272\n",
      "439\n",
      "1635\n",
      "1642\n",
      "133\n",
      "283\n",
      "272\n",
      "133\n",
      "F1\n",
      "0.9991\n",
      "0.9991\n",
      "0.9991\n",
      "0.8311\n",
      "0.8306\n",
      "0.9992\n",
      "0.9991\n",
      "0.9991\n",
      "0.9992\n",
      "FPR\n",
      "0.0002\n",
      "0.0002\n",
      "0.0003\n",
      "0.0012\n",
      "0.0012\n",
      "0.0001\n",
      "0.0002\n",
      "0.0002\n",
      "0.0001\n",
      "Positives/Attacks\n",
      "Errors (False Negatives)\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "530382\n",
      "532505\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "F1\n",
      "0.9979\n",
      "0.9979\n",
      "0.9977\n",
      "0.0480\n",
      "0.0406\n",
      "0.9980\n",
      "0.9979\n",
      "0.9979\n",
      "0.9980\n",
      "FNR\n",
      "0.0037\n",
      "0.0037\n",
      "0.0037\n",
      "0.9753\n",
      "0.9792\n",
      "0.0037\n",
      "0.0037\n",
      "0.0037\n",
      "0.0037\n",
      "reached. The results were validated through a 5-fold\n",
      "cross-validation.\n",
      "3) Hyperparameters tuning: the SVM-RBF requires tuning\n",
      "of the hyperparameters Î³ and C, which must be chosen\n",
      "accurately. We optimized them through a 5-fold cross-\n",
      "validated grid search with\n",
      "â€¢ C = {0.1, 1, 5, 10, 102, 103, 104, 105}\n",
      "â€¢ Î³ = {0.01, 0.1, 0.5, 1}\n",
      "4) Model robustness: once the best model configuration\n",
      "has been found, 10-fold cross-validation has been used\n",
      "for calculating, for each fold, the performance metrics\n",
      "\n",
      "---\n",
      "\n",
      "Since the misclassified attacks are always the same for both Ï‰u\n",
      "and Ï‰m (all Bot, Heartbleed and Infiltration attacks and three\n",
      "DDoS attacks), also the False Negative Rate (FNR) is always\n",
      "the same. Therefore, we must base the decision of the best\n",
      "model for Ïƒ < N and Ïƒ = N on the False Positive Rate (FPR).\n",
      "This leads to the selection of {Ïƒ5, Ï‰u} (FPR = 0.02%) and\n",
      "{ÏƒN, Ï‰m} (FPR = 0.01%) as the best configurations. These\n",
      "models not only achieve excellent detection performance for\n",
      "99.63% of the attacks tested, failing only for the attacks\n",
      "mentioned above, but also manage to maintain a very low\n",
      "FPR.\n",
      "B. Comparison with previous approaches\n",
      "By comparing our approach with the state of the art,\n",
      "as done in Table IV, it can be seen that with a smaller\n",
      "number of features required, better results are achieved in\n",
      "every evaluation metric considered. It should also be noted\n",
      "that the size of the training set is significantly smaller than\n",
      "that of other approaches, highlighting both the model ability to\n",
      "\n",
      "---\n",
      "\n",
      "Since the misclassified attacks are always the same for both Ï‰u\n",
      "and Ï‰m (all Bot, Heartbleed and Infiltration attacks and three\n",
      "DDoS attacks), also the False Negative Rate (FNR) is always\n",
      "the same. Therefore, we must base the decision of the best\n",
      "model for Ïƒ < N and Ïƒ = N on the False Positive Rate (FPR).\n",
      "This leads to the selection of {Ïƒ5, Ï‰u} (FPR = 0.02%) and\n",
      "{ÏƒN, Ï‰m} (FPR = 0.01%) as the best configurations. These\n",
      "models not only achieve excellent detection performance for\n",
      "99.63% of the attacks tested, failing only for the attacks\n",
      "mentioned above, but also manage to maintain a very low\n",
      "FPR.\n",
      "B. Comparison with previous approaches\n",
      "By comparing our approach with the state of the art,\n",
      "as done in Table IV, it can be seen that with a smaller\n",
      "number of features required, better results are achieved in\n",
      "every evaluation metric considered. It should also be noted\n",
      "that the size of the training set is significantly smaller than\n",
      "that of other approaches, highlighting both the model ability to\n",
      "    answer this question: What is the F1 score achieved by the proposed approach using the parameter set {Ïƒ5, Ï‰u}?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#### querying###\n",
    "\n",
    "question=\"What is the F1 score achieved by the proposed approach using the parameter set {Ïƒ5, Ï‰u}?\"\n",
    "genai.configure(api_key=\"AIzaSyAkaqkhODF6zP04i5IEqxkkLSNKfpMrMS8\")\n",
    "generation_config = {\"temperature\": 0.9, \"top_p\": 1, \"top_k\": 1, \"max_output_tokens\": 2048}\n",
    "\n",
    "    # 2. Initialize the model\n",
    "model = genai.GenerativeModel(\"gemini-pro\", generation_config=generation_config)\n",
    "\n",
    "\n",
    "query_text = question\n",
    "\n",
    "    # Search the DB\n",
    "results = db.similarity_search_with_relevance_scores(query_text, k=10)\n",
    "\n",
    "    # Extract context text from results\n",
    "context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _score in results])\n",
    "\n",
    "    # Create prompt for the generative model\n",
    "prompt = f\"\"\"Based on this content: {context_text}\n",
    "    answer this question: {query_text}\"\"\"\n",
    "print(prompt)\n",
    "    # Generate responses using the model\n",
    "responses = model.generate_content(prompt)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[text: \"0.9988\"\n",
       "]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses.parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "which model is better for learning with Tabular Data between GNM and MLP architecture?\n",
      "Based on this content: constraint of acyclicity of the underlying graph structure. This paper follows this direction.\n",
      "Specifically, the main contributions of the paper are summarized as follows:\n",
      "â€¢ We show that an MLP can be seen as an asynchronous message passing GNN applied to\n",
      "the MLPâ€™s graph representation.\n",
      "â€¢ We propose the Graph Neural Machine (GNM) model, a novel architecture for learn-\n",
      "ing with tabular data which generalizes the MLP architecture and hence, is a family of\n",
      "universal function approximators.\n",
      "â€¢ We evaluate the proposed model on several classification and regression datasets where it\n",
      "achieves performance better or comparable to the MLP architecture.\n",
      "2\n",
      "Related Work\n",
      "Tabular Data Learning with Graphs.\n",
      "Modelling tabular data with graphs has been an\n",
      "active research direction [18].\n",
      "Tabular data is represented by graphs in mainly three ways:\n",
      "data points as nodes, features as nodes and both as nodes (i. e., heterogeneous graphs). Edges\n",
      "\n",
      "---\n",
      "\n",
      "Graph Neural Machine: A New Model for Learning\n",
      "with Tabular Data\n",
      "Giannis Nikolentzos1\n",
      "nikolentzos@uop.gr\n",
      "Siyun Wang2\n",
      "siyun.wang@polytechnique.edu\n",
      "Johannes Lutzeyer2\n",
      "johannes.lutzeyer@polytechnique.edu\n",
      "Michalis Vazirgiannis2\n",
      "mvazirg@lix.polytechnique.fr\n",
      "1University of Peloponnese, Greece\n",
      "2LIX, Â´Ecole Polytechnique, IP Paris, France\n",
      "Abstract\n",
      "In recent years, there has been a growing interest in mapping data from different do-\n",
      "mains to graph structures. Among others, neural network models such as the multi-layer\n",
      "perceptron (MLP) can be modeled as graphs. In fact, MLPs can be represented as directed\n",
      "acyclic graphs. Graph neural networks (GNNs) have recently become the standard tool\n",
      "for performing machine learning tasks on graphs. In this work, we show that an MLP is\n",
      "equivalent to an asynchronous message passing GNN model which operates on the MLPâ€™s\n",
      "graph representation. We then propose a new machine learning model for tabular data, the\n",
      "\n",
      "---\n",
      "\n",
      "Table 1 illustrates the obtained results on the different classification datasets. We report the\n",
      "average accuracy and average macro F1-score and corresponding standard deviations on the\n",
      "test set across the 10 folds within the cross-validation. Overall, we observe that, with equal\n",
      "parameter budgets, the proposed GNM model outperforms the MLP architecture. More specif-\n",
      "ically, in terms of accuracy, GNM is the best performing model on 9 out of the 15 datasets,\n",
      "while in terms of F1-score, it outperforms the MLP on 10 out of the 15 classification datasets.\n",
      "As expected, the difference in performance between the two models is not very large, but in\n",
      "some cases, GNM provides significant improvements. For instance, on the DryBean dataset,\n",
      "GNM provides an absolute increase of 2.88% in accuracy over the MLP model.\n",
      "Table 2 illustrates the obtained results on the 6 regression datasets. We report the average\n",
      "MSE and average R2 score and corresponding standard deviations on the test set across the 10\n",
      "\n",
      "---\n",
      "\n",
      "that in most cases, the GNM model achieves better or comparable performance with the MLP\n",
      "architecture.\n",
      "References\n",
      "[1] Raman Arora, Amitabh Basu, Poorya Mianjy, and Anirbit Mukherjee.\n",
      "Understanding\n",
      "Deep Neural Networks with Rectified Linear Units. In 6th International Conference on\n",
      "Learning Representations, 2018.\n",
      "[2] Arthur Asuncion and David Newman.\n",
      "UCI machine learning repository.\n",
      "https://\n",
      "archive.ics.uci.edu/, 2007.\n",
      "12\n",
      "[3] Aristeidis Christoforidis, George Kyriakides, and Konstantinos Margaritis.\n",
      "A novel\n",
      "evolutionary algorithm for hierarchical neural architecture search.\n",
      "arXiv preprint\n",
      "arXiv:2107.08484, 2021.\n",
      "[4] Gregory F Cooper and Changwon Yoo. Causal Discovery from a Mixture of Experimental\n",
      "and Observational Data. In Proceedings of the 15th Conference on Uncertainty in Artificial\n",
      "Intelligence, pages 116â€“125, 1999.\n",
      "[5] Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, and George E Dahl.\n",
      "\n",
      "---\n",
      "\n",
      "parameters takes approximately the same time as training a GNM model that consists of 500k\n",
      "parameters. The same was observed in Figure 5, and we attribute this to the parallel processing\n",
      "abilities of GPUs.\n",
      "D\n",
      "Additional Training Curves\n",
      "Figure 8 illustrates the training curves of the GNM and MLP models on 4 datasets, namely Car,\n",
      "Phishing, Wireless and Connect4. We can see that on Phishing and Connect4, both models\n",
      "suffer from overfitting, but GNM is generally less prone to overfitting than MLP. On the Wireless\n",
      "dataset, we observe that the training procedure of MLP is somewhat unstable. This is not the\n",
      "case for the GNM model.\n",
      "20\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "loss\n",
      "~500k parameters\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "~1m parameters\n",
      "GNM train loss\n",
      "GNM val loss\n",
      "MLP train loss\n",
      "MLP val loss\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "epoch\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "loss\n",
      "~2m parameters\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "epoch\n",
      "~3m parameters\n",
      "(a) Car\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "0.0\n",
      "0.1\n",
      "0.2\n",
      "0.3\n",
      "0.4\n",
      "0.5\n",
      "loss\n",
      "~500k parameters\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "~1m parameters\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "epoch\n",
      "0.0\n",
      "0.1\n",
      "0.2\n",
      "0.3\n",
      "0.4\n",
      "0.5\n",
      "loss\n",
      "    answer this question: which model is better for learning with Tabular Data between GNM and MLP architecture?\n",
      "Based on the provided text, GNM is better for learning with Tabular Data than MLP architecture. The GNM model outperforms the MLP architecture on most datasets, in terms of accuracy and F1-score.\n",
      "How many samples were used in the training, validation, and test sets for the DNN model evaluation?\n",
      "Based on this content: for categorical variables in all datasets. More details about the datasets are given in Appendix B.\n",
      "6.2\n",
      "Experimental Setup\n",
      "To evaluate the different models, we performed 10-fold cross-validation. Within each fold, 10%\n",
      "of the training samples were used as validation set. All models were tested on the same splits.\n",
      "With regards to the hyperparameters of the models, for GNM, we chose the number of nodes\n",
      "(including input and output nodes) from {50, 100, 200, 300}. For MLP, we chose the number of\n",
      "hidden units from {32, 64, 128, 256}. On the Isolet dataset where the number of features m is\n",
      "equal to 617, we chose the number of nodes of GNM and the number of hidden units of the MLP\n",
      "from {800, 1000} and {512, 1024}, respectively. For both models, we also tuned the following\n",
      "two hyperparameters for each dataset: (1) the number of layers âˆˆ {2, 3, 4}; and (2) the dropout\n",
      "ratio âˆˆ {0, 0.2}. We applied the ReLU activation function to the representations of the neurons\n",
      "\n",
      "---\n",
      "\n",
      "All the layers except for the output use the rectified linear unit (ReLU) as the nonlinear activation\n",
      "function. Training, validation and test sets consisted of 179k, 1k and 20k samples respectively.\n",
      "The validation set is used to optimize the hyperparameters of the network such as number of\n",
      "hidden layers and their size, optimizer type, and learning rate using a hyperparameter optimizer\n",
      "Optuna [19]. A batch size of 200 is used and training is performed for 200 epochs. Adam is used\n",
      "as the optimizer [20] with a learning rate of 4.99 Ã— 10âˆ’4.\n",
      "x1\n",
      "x2\n",
      "x3\n",
      "...\n",
      "x336\n",
      "...\n",
      "R138\n",
      "...\n",
      "R433\n",
      "...\n",
      "R306\n",
      "...\n",
      "R501\n",
      "...\n",
      "R175\n",
      "y1\n",
      "y2\n",
      "y3\n",
      "...\n",
      "y127\n",
      "Fig. 8. Deep neural network with rectified linear unit (ReLU) activation function in the\n",
      "hidden layers. Input is a 336 bit long challenge and the output is an analog signal of\n",
      "length 127.\n",
      "As shown in Fig. 9 and 10, DNN provided the best predictions. However, as seen in Fig. 9b\n",
      "a decision boundary can still be drawn accurately. Indeed, this improvement comes from the\n",
      "\n",
      "---\n",
      "\n",
      "First, we show an evaluation of example models from a\n",
      "range of modalities, ranging from bias checking of facial de-\n",
      "tection via standard convolutional neural networks to limited\n",
      "inference of a language model.\n",
      "Second, we perform inference on a series of network archi-\n",
      "tectures at varying model sizes to estimate total memory\n",
      "4\n",
      "Verifiable Evaluation Attestations\n",
      "and compute time requirements, so as to estimate total costs\n",
      "of benchmarking. Code to rerun experiments and use the\n",
      "system can be found online2.\n",
      "5.1. Example Verifiable Model Attestations\n",
      "While general in design, the specifics of generating a veri-\n",
      "fiable evaluation attestation vary across model types. Any\n",
      "model that can be expressed as a computational graph in\n",
      "ONNX can be evaluated, and a sample of example models\n",
      "is shown in Table 1.\n",
      "The simplest such example of an evaluation would be a\n",
      "multi-layer perceptron (MLP) benchmarking on a small\n",
      "dataset such as MNIST (Deng, 2012).\n",
      "An inference proof is generated on each flattened image\n",
      "\n",
      "---\n",
      "\n",
      "the neurons. \n",
      "Moreover, observing the differences with the original \n",
      "image during the process (shown in figure 16), it can be con- \n",
      "cluded that the neurons that get more affected by change the \n",
      "ones from the input layer of the DNN. Therefore, an analy- \n",
      "sis of the input neurons of the DNN has been carried out to \n",
      "observe their evolution in the process of an adversarial ex- \n",
      "ample acquisition. A total of 69381 test images4 were used \n",
      "to study which neurons participated significantly in the pre- \n",
      "diction for a particular image class. A neuron participates \n",
      "in the prediction of an image if the assigned value in the \n",
      " \n",
      "4 https://www.kaggle.com/paultimothymooney/breast- \n",
      "histopathology-images \n",
      "behavior visualization is non-zero. For this purpose, the par- \n",
      "ticipation of each neuron per class was calculated counting \n",
      "the number times a neuron participated, i.e., the number of \n",
      "times the activation value different from zero. This value ob- \n",
      "Neuron \n",
      "Class 0 frequency \n",
      "Class 1 frequency\n",
      "\n",
      "---\n",
      "\n",
      "ing results across different models all achieved similar\n",
      "performances, as they all reached a saturation point with\n",
      "no further improvements beyond 32 epochs, leading to\n",
      "early termination.\n",
      "4.5\n",
      "Evaluation on occluded dataset\n",
      "The single-stage and two-staged models are compared\n",
      "by utilising an occluded dataset. The comparison needs\n",
      "to be revised as both single-stage and two-staged models\n",
      "may be influenced by their individual preparation meth-\n",
      "ods. However, the results are still comparable through\n",
      "careful analysis. The single-stage model is trained using\n",
      "the occluded dataset, enabling it to learn how to han-\n",
      "dle occlusions within the validation dataset, including\n",
      "occluded leaves.\n",
      "(a) ResNet15 with 4 Chan-\n",
      "nels.\n",
      "(b) sequential CNN model\n",
      "with 4 Channels.\n",
      "(c) ResNet15 with 3 Chan-\n",
      "nels.\n",
      "(d) ResNet50 with 3 Chan-\n",
      "nels.\n",
      "Figure 7: Validation training on different classification\n",
      "models.\n",
      "Table 4: Results of VGG16, ResNet50, ResNet15 and Sequential CNN model. Each training model was trained on\n",
      "    answer this question: How many samples were used in the training, validation, and test sets for the DNN model evaluation?\n",
      "This context does not mention the number of samples used in the training, validation, and test sets for the DNN model evaluation, so I cannot answer this question from the provided context.\n",
      "What is the Mean Absolute Error (MAE) for DirectLiNGAM with prior information (b) when using linear and guassian distribution?\n",
      "Based on this content: This equation reveals the crucial role played by the Gaussian\n",
      "Process prior in this otherwise unidentifiable problem and\n",
      "the need to have a dataset with variability across weights and\n",
      "latent variable locations. For each individual measurement\n",
      "of a data point i, this termâ€™s contribution only depends on\n",
      "the projection of the pure component signals sijÂ· onto riÂ·;\n",
      "this is due to the fact that Eq. (1) defines a Câˆ’1 dimensional\n",
      "hyperplane in sijÂ· of equal likelihood. The GP prior allows\n",
      "information to be shared between data points through the\n",
      "covariance in the latent space and can only be influenced by\n",
      "the likelihood if the dataset contains relevant information.\n",
      "Intuitively, for a set of data point I whose latent variables\n",
      "{xi}iâˆˆI are in the same neighborhood, i.e. close enough that\n",
      "they would share information via the GP prior, we would\n",
      "like variation in the fractional weights {riÂ·}iâˆˆI and would\n",
      "ideally like the fractional weights to span the simplex.\n",
      "\n",
      "---\n",
      "\n",
      "impacted by the unit or the length of the observed and predicted energy consumption time-series, it can well indicate\n",
      "their relative difference. In this context, a MAPE rate of 10% of lower should indicate a high prediction accuracy.\n",
      "While MAPE rates of 10â€“20%, 20â€“50%, and over 50% refer to good, reasonable, and inaccurate prediction accuracies,\n",
      "respectively. Moving on, the RMSE measures the square error of the predicted energy consumption time-series in\n",
      "comparison to the observed data before calculating the square root of the summation value. Due to that fact that\n",
      "the RMSE measures the average of the squared the errors, the values having large errors are weighted heavily and\n",
      "therefore the unacceptably large differences are revealed. On the contrary, MAE estimates the average amplitude of\n",
      "errors observed and predicted energy consumption time-series without disregarding the direction of errors. Thus, MAE\n",
      "\n",
      "---\n",
      "\n",
      "MLC, as now the Gaussian process factorizes over the M observations. To account for this we change the notation in\n",
      "this section so that U âˆˆ RMÃ—LÃ—C, made up of MC sets of ujc âˆˆ RL, and V âˆˆ RMÃ—LÃ—CÃ—A, made up of MC sets of\n",
      "ujc âˆˆ RLÃ—A, and has a prior\n",
      "p(U) =\n",
      "C\n",
      "Y\n",
      "c=1\n",
      "M\n",
      "Y\n",
      "j=1\n",
      "N\n",
      "\u0010\n",
      "ujc|0, Kjc\n",
      "VjcVjc\n",
      "\u0011\n",
      ",\n",
      "(52)\n",
      "where the kernel matrix is now a N Ã— N matrix with elements\n",
      "h\n",
      "Kjc\n",
      "VjcVjc\n",
      "i\n",
      "iiâ€² = kjc(xi, xiâ€²).\n",
      "(53)\n",
      "As it is impractical to find independent kernels and inducing points for each of the measurements and locations, for the\n",
      "remainder of this derivation we assume that kjc(xi, xiâ€²) = kc(xi, xiâ€²) and Vjc = Vc for all j, allowing us to maintain the\n",
      "same definitions for the kernel matrix KV V as defined in Equation (37), and the kernel matrices defined in Equation (38)\n",
      "and Equation (39) only need to be adapted to KxiV and Kxixi by changing the kernel function to\n",
      "kc(xi, xiâ€²) = Ïƒ2\n",
      "scexp\n",
      "\u00121\n",
      "2(xi âˆ’ xiâ€²)T Î²âˆ’1(xi âˆ’ xiâ€²)\n",
      "\u0013\n",
      ".\n",
      "(54)\n",
      "\n",
      "---\n",
      "\n",
      "model in about 10 hours with a converged Gelman-Rubin statistic\n",
      "lower than 1.008 for all our model parameters. In Table 5, we also\n",
      "summarise the MCMC best-fit labels of WD 1232+563, excluding\n",
      "the four undetected heavy elements with chondritic priors (i.e. Be, Cr,\n",
      "Mn, and Ni). We also report the systematic (ðœŽsys,ML) and statistical\n",
      "errors (ðœŽstat,MCMC) of each model parameter, obtained respectively\n",
      "from our sensitivity analysis of synthetic spectra (see Section 5.1)\n",
      "and our MCMC fit. The former measure the errors of ceciliaâ€™s pre-\n",
      "dictions arising from the ML-based spectral interpolation process,\n",
      "while the latter represent the errors of the SDSS data and are hence\n",
      "observational in nature. Assuming Gaussian and uncorrelated errors,\n",
      "we can approximate the total uncertainty of a model parameter (ðœŽtot)\n",
      "by adding these two sources of errors in quadrature (together with\n",
      "any other systematic errors, or ðœŽother, coming from the atmosphere\n",
      "models, which we do not consider in this work),\n",
      "ðœŽtot =\n",
      "âˆšï¸ƒ\n",
      "\n",
      "---\n",
      "\n",
      "(xiÎ»j)V riÂ·rT\n",
      "iÂ·K(xiÎ»j)V +\n",
      "N âˆ—\n",
      "X\n",
      "i=1\n",
      "M\n",
      "X\n",
      "j=1\n",
      "KT\n",
      "(XiÎ»j)V\n",
      "Mixed-Output Gaussian Process Latent Variable Models\n",
      "B.2. Derivation of the ELBO with Independent Measurements\n",
      "Note: The notation for this derivation differes slightly from the derivation above and the table given in Appendix A. Where\n",
      "there are differences they are stated here.\n",
      "In this derivation we present a derivation of the ELBO where we do not assume that the measurement is smooth and can\n",
      "be described by a Gaussian Process across the observed inputs. The change in the Gaussian Process prior is that it it now\n",
      "factorizes across the MC vectors of sÂ·jc âˆˆ RN\n",
      "p(S) =\n",
      "C\n",
      "Y\n",
      "c=1\n",
      "M\n",
      "Y\n",
      "j=1\n",
      "N(sÂ·jc|0, Kjc\n",
      "VjcVjc).\n",
      "(51)\n",
      "As we are working with the variational sparse changing the prior for S requires changing the inducing points and their prior\n",
      "such that they are drawn from the output of the GP. This requires increasing the number of inducing points from LC to\n",
      "    answer this question: What is the Mean Absolute Error (MAE) for DirectLiNGAM with prior information (b) when using linear and guassian distribution?\n",
      "The provided context does not contain information about the Mean Absolute Error (MAE) for DirectLiNGAM with prior information (b) when using linear and Gaussian distribution. Thus, I cannot answer this question from the provided context.\n",
      "how many model parameters has the VAE (decoder)  for generating an inference proof?\n",
      "Based on this content: the inference of the model. This setup step composes many\n",
      "different proof arguments to provide an extremely flexible\n",
      "approach to model setup that works for the vast majority of\n",
      "ML model architectures, with technical details of how this\n",
      "was achieved in Appendix A.1.\n",
      "Second, an evaluation dataset is selected to confirm per-\n",
      "formance or check for bias. Inference over the dataset is\n",
      "performed using standard practices to produce a set of input\n",
      "files containing input-output pairs (x, y).\n",
      "Third, for each data pair, a witness file is generated (includ-\n",
      "3\n",
      "Verifiable Evaluation Attestations\n",
      "ing some quantization) for the (x, y) pair, and a computa-\n",
      "tional inference proof is created as a zkSNARK. This proof\n",
      "takes W as a secret input value to the circuit and x as a\n",
      "public input value and uses the previous commitment pk\n",
      "to generate the proof Ï€. This Prove(pk, W, x, y) â†’ Ï€ âŠƒ\n",
      "{H(W), y} is a computationally expensive step, with more\n",
      "details in Appendix A.3.\n",
      "\n",
      "---\n",
      "\n",
      "can create minor challenges for proofs due to the random\n",
      "generation. Instead we prove a partial execution of the VAE\n",
      "showing decoding from the latent space. Here the witness\n",
      "inputs are points in the latent space to be passed into the\n",
      "decoder and a naive bundle will contain these points with\n",
      "proven image outputs from the latent space. This provides\n",
      "an interesting approach to allowing for verifiable statements\n",
      "about the latent space. So long as the space has been suffi-\n",
      "ciently sampled (such as via a grid across the space centered\n",
      "around the mean) an inspector could see if any undesirable\n",
      "outputs are generated or inspect to see the degree to which\n",
      "certain properties of the latent space (such as race in facial\n",
      "images) are clustered.\n",
      "This generative approach can be applied to small lan-\n",
      "guage models as well. Autoregressive models such as an\n",
      "LSTM (Sak et al., 2014) or a decoder-only transformer (Rad-\n",
      "ford et al., 2019) require a proof for each inference (e.g.,\n",
      "\n",
      "---\n",
      "\n",
      "stakes scenarios where model reliability and fairness are\n",
      "paramount. The system packages together repeated model\n",
      "inference proofs to demonstrate the accuracy of models\n",
      "either through simple bundling of small proofs and verifica-\n",
      "tion files or through meta-proofs of performance over model\n",
      "inference proofs. The systemâ€™s flexibility was demonstrated\n",
      "across a range of ML models ranging from small percep-\n",
      "trons and regression models to medium-sized transformers.\n",
      "The system faces challenges, primarily related to the com-\n",
      "putational cost and time required for generating proofs, es-\n",
      "pecially for large-scale models. The trade-off between accu-\n",
      "racy and resource demands during the proof generation pro-\n",
      "cess remains a critical consideration. Future improvements\n",
      "in the speed and efficiency of the zkSNARKs, possibly\n",
      "through hardware acceleration or proving system changes,\n",
      "could significantly improve the cost and applicability of\n",
      "this approach. Moreover, the discussion around private\n",
      "\n",
      "---\n",
      "\n",
      "Verifiable Evaluation Attestations\n",
      "els, such as other autogressive models or new language\n",
      "model architecture, diffusion models which behave much\n",
      "like VAE decoders, or sequence to sequence models such\n",
      "as Wav2Vec (Baevski et al., 2020) or Whisper (Fedus et al.,\n",
      "2022) which apply the public tokenizer assumption to au-\n",
      "dio processing and generate a sequence output as witness.\n",
      "Larger models, such as a mixture of experts, are also possi-\n",
      "ble, with model size being the only constraint. As we see\n",
      "below, proof time and resource requirements grow dramati-\n",
      "cally with large models.\n",
      "5.2. Increasing Costs from Increasing Size\n",
      "0\n",
      "2\n",
      "4\n",
      "Model Parameters\n",
      "Ã—107\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "MACs (proxy for FLOPs)\n",
      "Ã—107\n",
      "0\n",
      "2\n",
      "4\n",
      "MACs\n",
      "Ã—107\n",
      "0.0\n",
      "0.5\n",
      "1.0\n",
      "1.5\n",
      "2.0\n",
      "2.5\n",
      "Number of Constraints\n",
      "Ã—107\n",
      "0\n",
      "1\n",
      "2\n",
      "Number of Constraints (ncon) Ã—107\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "Proof Time (s)\n",
      "3.5 Ã— 10âˆ’04ncon\n",
      "0\n",
      "1\n",
      "2\n",
      "Number of Constraints (ncon) Ã—107\n",
      "1 MB\n",
      "1 GB\n",
      "100 GB\n",
      "File Size\n",
      "CNN\n",
      "MLP\n",
      "Attn\n",
      "Proving Key (pk)\n",
      "Veriï¬cation Key (vk)\n",
      "Proof File (Ï€)\n",
      "9.5 Ã— 103ncon\n",
      "5.5ncon\n",
      "\n",
      "---\n",
      "\n",
      "9.9 Ã— 10âˆ’4ncon + 6 Ã— 104\n",
      "Figure 2. Time and storage requirements for model inference\n",
      "proofs for increasing model sizes across multi-layered perceptions\n",
      "(MLP), convolutional neural networks (CNN), and attention-based\n",
      "transformers (Attn). Model requirements scale linearly with the\n",
      "number of constraints in the proof, which is driven by the number\n",
      "of operations used in a model inference. Model parameters het-\n",
      "erogeneously impact the number of operations in model inference.\n",
      "Inferences run on a commodity compute cluster slower than in\n",
      "Table 1.\n",
      "As has been seen widely in ML, increasing numbers of\n",
      "model parameters can lead to dramatically increased perfor-\n",
      "mance (Kaplan et al., 2020). However, these larger models\n",
      "also require more computation and greater resource require-\n",
      "ments for inference. The same is true when performing\n",
      "inference of models inside zkSNARKs.\n",
      "Increasing the number of operations a model performsâ€”\n",
      "often measured in multiplyâ€“accumulate operations (MACs)\n",
      "    answer this question: how many model parameters has the VAE (decoder)  for generating an inference proof?\n",
      "This document does not provide the number of model parameters of the VAE (decoder) for inference proof generation.\n",
      "what is the purpose of kernel mean embedding according to Muandet?\n",
      "Based on this content: nel mean embedding using Câˆ—-algebras (Hashimoto\n",
      "et al., 2022). Theoretically, to define the kernel mean\n",
      "embedding, we need the Riesz representation theo-\n",
      "rem. Although the Riesz representation theorem is\n",
      "always true for Hilbert spaces, we do not always have\n",
      "the corresponding theorem for Hilbert Câˆ—-modules.\n",
      "According to Skeide (2000), we have the Riesz rep-\n",
      "resentation theorem if the Hilbert Câˆ—-module is in\n",
      "a special class called von-Neumann module (see Def-\n",
      "inition 4.4 in Skeide 2000).\n",
      "In this case, instead\n",
      "of the [0, 1]-valued (more generally, finite signed or\n",
      "complex-valued) measure, we can map an A-valued\n",
      "measure (Hashimoto et al., 2021) to a vector in an\n",
      "RKHM. A-valued measures are defined as the spe-\n",
      "cial case of vector measures (Dinculeanu, 1967, 2000).\n",
      "Spectral measures and positive operator-valued mea-\n",
      "sures are examples of B(W)-valued measures for some\n",
      "Hilbert space W. Positive operator-valued measures\n",
      "are introduced in quantum mechanics and are used\n",
      "\n",
      "---\n",
      "\n",
      "enables us to evaluate the value of a function at a\n",
      "point using the inner product, which makes it easy\n",
      "for us to implement algorithms and analyze them\n",
      "theoretically. Moreover, we can apply kernel methods\n",
      "to probabilistic and statistical settings by embedding\n",
      "probability measures in an RKHS. This embedding\n",
      "is called the kernel mean embedding. However, since\n",
      "RKHSs (resp. vvRKHSs) are complex- (resp. vector-\n",
      ") valued function spaces, the output of the models\n",
      "is usually complex- or vector-valued. In addition,\n",
      "appropriate ways of the construction of positive def-\n",
      "inite kernels are not trivial. The generalization of\n",
      "RKHS by means of the Câˆ—-algebra enables us to out-\n",
      "put more general data, such as functions and opera-\n",
      "tors (Hashimoto et al., 2021). Moreover, Câˆ—-algebras\n",
      "give us a method to construct Câˆ—-algebra-valued pos-\n",
      "1\n",
      "arXiv:2402.02637v1  [cs.LG]  4 Feb 2024\n",
      "itive definite kernels for structured data (Hasimoto\n",
      "et al., 2023a). The noncommutative product struc-\n",
      "\n",
      "---\n",
      "\n",
      "a. On the other hand, the operator norm of a is\n",
      "calculated as maxâˆ¥vâˆ¥=1\n",
      "Pd\n",
      "i=1 | Pd\n",
      "j=1 ai,jvj|2. Since\n",
      "| Pd\n",
      "j=1 ai,jvj| â‰¤ Pd\n",
      "j=1 |ai,j| and Pd\n",
      "i=1 |vj|2 = 1, the\n",
      "dependency of the operator norm on the dimension\n",
      "d is milder than that of the Hilbertâ€“Schmidt norm.\n",
      "This fact is useful for deriving the generalization\n",
      "bound of the kernel ridge regression. By virtue of\n",
      "introducing Câˆ—-algebra and using the operator norm,\n",
      "we can alleviate the dependency of the generalization\n",
      "bound on the output dimension (Hasimoto et al.,\n",
      "2023b).\n",
      "5.1.1\n",
      "Kernel mean embedding\n",
      "Kernel mean embedding enables us to generalize ker-\n",
      "nel methods to analyze the distribution of data Muan-\n",
      "det et al. (2017); Sriperumbudur et al. (2011). We\n",
      "define a map that maps a distribution to a vector in\n",
      "an RKHS by integrating the positive definite kernel\n",
      "with respect to the distribution. This map is called\n",
      "kernel mean embedding and enables us to analyze the\n",
      "distribution in the RKHS. We can generalize the ker-\n",
      "\n",
      "---\n",
      "\n",
      "In Proceedings of the 22nd International Conference\n",
      "on Artificial Intelligence and Statistics (AISTATS),\n",
      "2019.\n",
      "Lance, E. C.\n",
      "Hilbert Câˆ—-modules â€“ a Toolkit for\n",
      "Operator Algebraists. London Mathematical Society\n",
      "Lecture Note Series, vol. 210. Cambridge University\n",
      "Press, 1995.\n",
      "11\n",
      "Manuilov, V. and Troitsky, E. Hilbert Câˆ—- and W âˆ—-\n",
      "modules and their morphisms. Journal of Mathe-\n",
      "matical Sciences, 98:137â€“201, 2000.\n",
      "McMahan, B., Moore, E., Ramage, D., Hampson, S.,\n",
      "and Arcas, B. A. y. Communication-Efficient Learn-\n",
      "ing of Deep Networks from Decentralized Data. In\n",
      "Proceedings of the 20th International Conference\n",
      "on Artificial Intelligence and Statistics (AISTATS),\n",
      "2017.\n",
      "Muandet, K., Fukumizu, K., Sriperumbudur, B., and\n",
      "SchÂ¨olkopf, B. Kernel mean embedding of distri-\n",
      "butions: A review and beyond. Foundations and\n",
      "Trends in Machine Learning, 10(1â€“2), 2017.\n",
      "Murphy, G. J. C*-Algebras and Hilbert Space Opera-\n",
      "tors. Academic Press, 1990.\n",
      "Nitanda,\n",
      "A. and Suzuki,\n",
      "T.\n",
      "Stochastic par-\n",
      "ticle\n",
      "gradient\n",
      "descent\n",
      "\n",
      "---\n",
      "\n",
      "in extracting information on the probabilities of out-\n",
      "comes from a state (Holevo, 2011). Using the kernel\n",
      "mean embedding for A-valued measures, we can ana-\n",
      "lyze positive operator-valued measures.\n",
      "5.1.2\n",
      "Deep learning with kernels\n",
      "Combining kernel methods and deep learning to take\n",
      "advantage of the representation power and the the-\n",
      "oretical solidness of kernel methods, and the flexi-\n",
      "bility of deep learning has been investigated Cho &\n",
      "Saul (2009); Gholami & Hajisami (2016); Bohn et al.\n",
      "(2019); Laforgue et al. (2019). A generalization of\n",
      "these methods to RKHMs is also proposed (Hasimoto\n",
      "et al., 2023b). In this method, instead of consider-\n",
      "ing the composition of functions in RKHSs, we con-\n",
      "sider the composition of functions in RKHMs. The\n",
      "high representation power of RKHMs and the prod-\n",
      "uct structure of Câˆ—-algebras make the deep learning\n",
      "method with kernels more powerful.\n",
      "5.2\n",
      "Neural network parameters\n",
      "In classical neural networks, the input and output\n",
      "    answer this question: what is the purpose of kernel mean embedding according to Muandet?\n",
      "Kernel mean embedding generalizes kernel methods to analyze the distribution of data. It maps a distribution to a vector in an RKHS by integrating the positive definite kernel with respect to the distribution. This map enables us to analyze the distribution in the RKHS.\n",
      "Does p-value vs. attack budget Ïµ for ResNet101 reach 1.0 when using l2 norm?\n",
      "Based on this content: particular, given a specific machine learning model under a specific adversarial attack (with fixed\n",
      "budget and norm), one can leverage the different p-value vs. attack budget plots in Figs. 1â€“4 to\n",
      "establish whether such a model is (Î± = 0.10, Î¶ = 0.05)â€“safe under such an attack depending on\n",
      "whether the p-value is higher or lower than Î¶ = 0.05 (corresponding to the horizontal dashed line in\n",
      "each plot). For example, under a white-box AutoAttack with an â„“2-ball with radius Ïµ = 0.026, one\n",
      "10\n",
      "(a) AT-ResNet, ð‘™! norm\n",
      "(b) CLIP-ViT, ð‘™! norm\n",
      "(c) AT-ResNet, ð‘™\" norm\n",
      "(d) CLIP-ViT, ð‘™\" norm\n",
      "Figure 4: p-value vs. attack budget Ïµ for AT-ResNets and CLIP-ViTâ€™s under SquareAttack with l2\n",
      "norm and lâˆž norm. In (c) and (d), the curves of Rob-R50-linf-4 and Rob-R50-linf-8 overlap because\n",
      "they exhibit similar empirical risks.\n",
      "can establish from Fig. 1a that ResNet34 is (Î±=0.10, Î¶=0.05)-safe, while ResNet50 and ResNet101\n",
      "\n",
      "---\n",
      "\n",
      "particular, given a specific machine learning model under a specific adversarial attack (with fixed\n",
      "budget and norm), one can leverage the different p-value vs. attack budget plots in Figs. 1â€“4 to\n",
      "establish whether such a model is (Î± = 0.10, Î¶ = 0.05)â€“safe under such an attack depending on\n",
      "whether the p-value is higher or lower than Î¶ = 0.05 (corresponding to the horizontal dashed line in\n",
      "each plot). For example, under a white-box AutoAttack with an â„“2-ball with radius Ïµ = 0.026, one\n",
      "10\n",
      "(a) AT-ResNet, ð‘™! norm\n",
      "(b) CLIP-ViT, ð‘™! norm\n",
      "(c) AT-ResNet, ð‘™\" norm\n",
      "(d) CLIP-ViT, ð‘™\" norm\n",
      "Figure 4: p-value vs. attack budget Ïµ for AT-ResNets and CLIP-ViTâ€™s under SquareAttack with l2\n",
      "norm and lâˆž norm. In (c) and (d), the curves of Rob-R50-linf-4 and Rob-R50-linf-8 overlap because\n",
      "they exhibit similar empirical risks.\n",
      "can establish from Fig. 1a that ResNet34 is (Î±=0.10, Î¶=0.05)-safe, while ResNet50 and ResNet101\n",
      "\n",
      "---\n",
      "\n",
      "are not; likewise, under the same attack with Ïµ = 0.026, Fig. 1.b reveals that ViT-S is not (Î±=0.10,\n",
      "Î¶=0.05)-safe, while the two larger models are safe.\n",
      "Moreover, one can leverage the p-value vs attack budget plots in Figs. 1â€“4 to establish a range of attack\n",
      "budgets under which a specific model subject to a specific adversarial attack is (Î± = 0.10, Î¶ = 0.05)-\n",
      "safe. For example, Fig. 1a shows that ResNet34 is (Î± = 0.10, Î¶ = 0.05)-safe under AutoAttack with\n",
      "l2 norm provided that the attack budget is smaller than (roughly) 0.027; in turn, Fig. 1b suggests that\n",
      "ViT-S is (Î± = 0.10, Î¶ = 0.05)-safe under AutoAttack with l2 norm provided that the attack budget is\n",
      "smaller than (roughly) 0.022. Naturally, we can adopt a similar analysis to establish (Î±, Î¶)-safety\n",
      "guarantees of the other models in the presence of the various attacks under consideration by inspecting\n",
      "Figs. 1â€“4.\n",
      "Importantly, our framework leads to results that are consistent with existing results in the literature,\n",
      "\n",
      "---\n",
      "\n",
      "are not; likewise, under the same attack with Ïµ = 0.026, Fig. 1.b reveals that ViT-S is not (Î±=0.10,\n",
      "Î¶=0.05)-safe, while the two larger models are safe.\n",
      "Moreover, one can leverage the p-value vs attack budget plots in Figs. 1â€“4 to establish a range of attack\n",
      "budgets under which a specific model subject to a specific adversarial attack is (Î± = 0.10, Î¶ = 0.05)-\n",
      "safe. For example, Fig. 1a shows that ResNet34 is (Î± = 0.10, Î¶ = 0.05)-safe under AutoAttack with\n",
      "l2 norm provided that the attack budget is smaller than (roughly) 0.027; in turn, Fig. 1b suggests that\n",
      "ViT-S is (Î± = 0.10, Î¶ = 0.05)-safe under AutoAttack with l2 norm provided that the attack budget is\n",
      "smaller than (roughly) 0.022. Naturally, we can adopt a similar analysis to establish (Î±, Î¶)-safety\n",
      "guarantees of the other models in the presence of the various attacks under consideration by inspecting\n",
      "Figs. 1â€“4.\n",
      "Importantly, our framework leads to results that are consistent with existing results in the literature,\n",
      "\n",
      "---\n",
      "\n",
      "SquareAttack than in AutoAttack, we average the empirical risks over 10 trials with different random\n",
      "seeds for a more accurate p-value.\n",
      "Adversarial Attacks with Free Hyperparameters. We next consider a NES attack where the\n",
      "attacker can choose the two hyper-parameters Î»Ïƒ and Î»Î·, shown in Tab. 1, to test the ability of the\n",
      "9\n",
      "(a) ResNet, ð‘™! norm\n",
      "(b) ViT, ð‘™! norm\n",
      "(c) ResNet, ð‘™\" norm\n",
      "(d) ViT, ð‘™\" norm\n",
      "Figure 3: p-value vs. attack budget Ïµ for ResNets and ViTâ€™s under SquareAttack with l2 norm and lâˆž\n",
      "norm.\n",
      "(a) Sparse Grid\n",
      "Ïµ\n",
      "0.10\n",
      "0.15\n",
      "0.2\n",
      "0.25\n",
      "0.3\n",
      "p-value\n",
      "0.000\n",
      "0.009\n",
      "0.423\n",
      "1.000\n",
      "1.000\n",
      "(b) Dense Grid\n",
      "Ïµ\n",
      "0.14\n",
      "0.15\n",
      "0.16\n",
      "0.17\n",
      "0.18\n",
      "p-value\n",
      "0.000\n",
      "0.009\n",
      "0.029\n",
      "0.134\n",
      "0.346\n",
      "(c) GP-UCB\n",
      "Ïµ\n",
      "0.14\n",
      "0.15\n",
      "0.16\n",
      "0.17\n",
      "0.18\n",
      "p-value\n",
      "0.000\n",
      "0.009\n",
      "0.029\n",
      "0.134\n",
      "0.346\n",
      "Table 2: NES attack with GP-UCB optimization (Alg. 1) for hyperparameter selection with ResNet50\n",
      "and l2 norm.\n",
      "BO algorithm to certify machine learning model robustness. Bayesian optimization is initialized\n",
      "    answer this question: Does p-value vs. attack budget Ïµ for ResNet101 reach 1.0 when using l2 norm?\n",
      "The provided text does not have information about the p-value vs. attack budget Ïµ for ResNet101 using l2 norm.\n",
      "why is the approach PROSAC presented?\n",
      "Based on this content: difficulty of understanding the source code (Question 1) for the \n",
      "trials at the University of Bari and PUC-Rio but could be rejected \n",
      "for the SERPRO trial and considering the aggregated results. Still, \n",
      "it is possible to observe a slightly higher perceived ease of under- \n",
      "standing for the SOLID treatment in all trials (cf. Figures 4 and \n",
      "5). Not achieving statistically significant differences between the \n",
      "University of Bari and PUC-Rio could be due to the slightly smaller \n",
      "sample size. \n",
      "While a complete qualitative analysis of the open-ended ques- \n",
      "tions is out of the scope of this paper, we used this data aiming \n",
      "at better understanding situations in which HO could not be re- \n",
      "jected. At the University of Bari, three participants of the SOLID \n",
      "treatment considered the code hard to understand. Out of these \n",
      "three, two explained their answers. One mentioned â€œIâ€™m quite new \n",
      "in the ML field. Iâ€™ve just studied some concepts for my personal\n",
      "\n",
      "---\n",
      "\n",
      "projects\" while the other one justified â€œI didnâ€™t understand the \n",
      "part of features and labels because I have no solid base of ML.\" \n",
      "Hence, their difficulties were apparently more closely related to \n",
      "specific ML-related implementations than to the code structure. At \n",
      "PUC-Rio, only one participant of the SOLID treatment considered \n",
      "the code hard to understand, justifying it with a â€œlack of practice \n",
      "with object-oriented programming\". Another important aspect is \n",
      "that the original code was relatively small, potentially making the \n",
      "benefits of distributing responsibilities clearer for the subsequent \n",
      "maintenance scenarios. Indeed, many subjects of the Unstructured \n",
      "treatment also found the code easy to understand. The limited sam- \n",
      "ple size within a single trial can have isolated cases of confounding \n",
      "factors leading to non-statistically significant results in some cases. \n",
      "The SRP questions regarding clearly distributed and defined\n",
      "\n",
      "---\n",
      "\n",
      "treatments was the application of the SRP principle as described. \n",
      "The results at the University of Bari, PUC-Rio, SERPRO, and the \n",
      "aggregated results are shown in Figures 4, 5, 6, and 7. \n",
      " \n",
      " \n",
      "Figure 4: Question 1 results at University of Bari: Perception \n",
      "about understanding the source code. \n",
      " \n",
      "While it is possible to observe higher perceived ease of under- \n",
      "standing for the SOLID treatment in all cases (e.g., higher prevalence \n",
      "of the \"Very easy\" and \"easy\" categories and a lower prevalence \n",
      " \n",
      " \n",
      " \n",
      "Figure 5: Question 1 results at PUC-Rio: Perception about \n",
      "understanding the source code. \n",
      " \n",
      " \n",
      "Figure 6: Question 1 results at SERPRO: Perception about \n",
      "understanding the source code. \n",
      " \n",
      " \n",
      "Figure 7: The overall result for Question 1: Perception about \n",
      "understanding the source code. \n",
      " \n",
      "of the \"Hard\" category), the observed differences are statistically \n",
      "significant only for the SERPRO company and for the aggregated \n",
      "data (cf. Table 6). The subsequent close-ended questions assess the\n",
      "\n",
      "---\n",
      "\n",
      "responsibilities (Question 3), single responsibilities (Question 5), \n",
      "and single reasons for change (Question 7) allowed rejecting H0, \n",
      "with significantly low p-values and high effect sizes. These results \n",
      "indicate that when it comes to specific aspects related to SRP, a \n",
      "significant and positive impact was perceived by the participants. \n",
      " \n",
      " \n",
      " \n",
      "5.2 OCP - Open-Closed Principle \n",
      "For OCP, the null hypothesis (H0) could also not be rejected con- \n",
      "cerning the overall perception of the difficulty of understanding the \n",
      "related source code (Question 9) for the University of Bari and PUC- \n",
      "Rio. Nevertheless, a slightly higher perceived ease of understanding \n",
      "was observed for the SOLID treatment for all trials, even for the \n",
      "University of Bari and PUC-Rio (the difference can be observed in \n",
      "the graphs provided in the online material [4]). Not achieving sta- \n",
      "tistically significant differences could be due to the smaller sample \n",
      "size. Indeed, it was possible to reject H0 for the SERPRO trial and\n",
      "\n",
      "---\n",
      "\n",
      "the prompt engineering that obliges the network to elucidate the rationale behind its outputs, and (2) the prediction\n",
      "ensemble methodology to extract the result ensuring all models concur in providing identical reasoning.\n",
      "17\n",
      "References\n",
      "[1] Sean Wu, Michael Koo, Lesley Blum, Andy Black, Liyo Kao, Zhe Fei, Fabien Scalzo, and Ira Kurtz. Benchmarking\n",
      "open-source large language models, GPT-4 and Claude 2 on multiple-choice questions in nephrology. NEJM AI,\n",
      "page AIdbp2300092, 2024.\n",
      "[2] Fatima N Mirza, Oliver Y Tang, Ian D Connolly, Hael A Abdulrazeq, Rachel K Lim, G Dean Roye, Cedric Priebe,\n",
      "Cheryl Chandler, Tiffany J Libby, Michael W Groff, et al. Using ChatGPT to facilitate truly informed medical\n",
      "consent. NEJM AI, page AIcs2300145, 2024.\n",
      "[3] Peter Lee, Sebastien Bubeck, and Joseph Petro. Benefits, limits, and risks of GPT-4 as an AI chatbot for medicine.\n",
      "New England Journal of Medicine, 388(13):1233â€“1239, 2023.\n",
      "    answer this question: why is the approach PROSAC presented?\n",
      "I apologize, but the provided text does not mention anything about the PROSAC approach, so I cannot answer your question based on the provided text.\n",
      "what is the MSE of SE(3) TRASFORMER in the N-body dynamics prediction task?\n",
      "Based on this content: Weisfeiler Leman for Euclidean Equivariant Machine Learning\n",
      "In physical systems, there may be external forces present\n",
      "that act independently on the particles. Therefore, We also\n",
      "test our model on the N-Body problem with the natural exter-\n",
      "nal force fields of Gravity and a Lorentz-like force (derived\n",
      "from a magnetic field acting on the charged particles.) We\n",
      "then compare the performance of WeLNet to baselines that\n",
      "were designed for such tasks, such as ClofNet (Du et al.,\n",
      "2022). We find that WeLNet has significantly better results\n",
      "with the gravitational force and comparable results with the\n",
      "Lorentz-like force field. Results are shown in Table 2.\n",
      "Table 1. Test MSE for the N-body dynamics prediction task. We\n",
      "compare to the previous SOTA, Transformer-PS (Kim et al., 2023),\n",
      "and other baselines MC-EGNN (Levy et al., 2023), CN-GNN\n",
      "(Kaba et al., 2023), SEGNN (Brandstetter et al., 2021), FA-GNN\n",
      "(Puny et al., 2021), ClofNet(Du et al., 2022) and EGNN (Victor\n",
      "Garcia Satorras, 2021).\n",
      "METHOD\n",
      "MSE\n",
      "\n",
      "---\n",
      "\n",
      "We have proven that this architecture is universal when\n",
      "PPGN is used for five iterations, and the internal MLPs\n",
      "in the PPGN architecture are shallow MLPs with analytic\n",
      "non-polynomial activations whose feature dimension can\n",
      "be as small as 12n + 1. Further implementation details are\n",
      "described in Appendix B.\n",
      "7. Experiments\n",
      "In this section we experimentally evaluate the performance\n",
      "of WeLNet on equivariant tasks. Full details on the experi-\n",
      "ments can be found in Appendix B\n",
      "7.1. N-Body Problem\n",
      "The N-body problem is a classic problem in the physical\n",
      "sciences, in which the model has to predict the trajectory\n",
      "of bodies in Euclidean space based on their initial position,\n",
      "physical properties (e.g. charge), and initial velocity. We\n",
      "test our model on the N-body dynamics prediction task (Vic-\n",
      "tor Garcia Satorras, 2021), a highly popular dataset that is a\n",
      "standard benchmark for Euclidean equivariant models. We\n",
      "find that WeLNet achieves a new state-of-the-art result.\n",
      "Results are shown in Table 1.\n",
      "7\n",
      "\n",
      "---\n",
      "\n",
      "1998.10511322\n",
      "30\n",
      "9 Appendix: Resolution of Neuber-type method\n",
      "with material law\n",
      "This section details the resolution of the Neuber-type method in conjunction with\n",
      "the material law chosen. We start with the Neuber-type equation reduced to 1-D via\n",
      "the proportionality evolution functions s(t), e(t) and f(t). The last peak encountered\n",
      "during cyclic loading is kept in memory via so and eo. Similarly, fo is the value of load\n",
      "at the last peak. Here, the proportionality evolution functions s(t) and e(t) need to\n",
      "be calculated for each increment of time, in order to be able to calculate the full 3-D\n",
      "approximated stress and strain tensors.\n",
      "(s âˆ’ so)(e âˆ’ eo) = (f âˆ’ fo)2\n",
      "(43)\n",
      "To simplify the notation in the following equations, the following shorthand is used:\n",
      "g(t) = (f(t) âˆ’ f(t)o)2, âˆ†os = (s âˆ’ so) and âˆ†oe = (e âˆ’ eo).\n",
      "âˆ†osâˆ†oe = g(t)\n",
      "(44)\n",
      "Plugging the expression for âˆ†oe that comes from the material law (28) into the\n",
      "reduced Neuber-type equation (44) gives a second order polynomial equation for âˆ†os:\n",
      "\n",
      "---\n",
      "\n",
      "sequence, as well as sequence candidates that meet a required force-extension behavior and various other properties.\n",
      "Fine-tuning is conducted using a dataset derived from molecular dynamics (MD) simulations[81]. Sample tasks for the\n",
      "model include:\n",
      "CalculateForce<GEECDCGSPSNPCCDAATCKLRPGAQCADGLCCDQCRFKKKRTICRIARGDFPDDRCTGQSADCPRWN> [0.262]\n",
      "CalculateEnergy<GEECDCGSPSNPCCDAATCKLRPGAQCADGLCCDQCRFKKKRTICRIARGDFPDDRCTGQSADCPRWN> [0.220]\n",
      "CalculateForceEnergy<GEECDCGSPSNPCCDAATCKLRPGAQCADGLCCDQCRFKKKRTICRIARGDFPDDRCTGQSADCPRWN> [0.262,0.220]\n",
      "CalculateForceHistory<GEECDCGSPSNPCCDAATCKLRPGAQCADGLCCDQCRFKKKRTICRIARGDFPDDRCTGQSADCPRWN>\n",
      "[0.004,0.034,0.125,0.142,0.159,0.102,0.079,0.073, 0.131,0.105,0.071,0.058,0.072,0.060,0.049,0.114,\n",
      "0.122,0.108,0.173,0.192,0.208,0.153,0.212,0.222, 0.244]\n",
      "GenerateForce<0.262> [GEECDCGSPSNPCCDAATCKLRPGAQCADGLCCDQCRFKKKRTICRIARGDFPDDRCTGQSADCPRWN]\n",
      "GenerateForce<0.220> [GEECDCGSPSNPCCDAATCKL RPGAQCADGLCCDQCRFKKKRTICRIARGDFPDDRCTGQSADCPRWN]\n",
      "\n",
      "---\n",
      "\n",
      "Note that Equations 14-15 are of the same form as the equivariant pooing layers defined in Equations 8-9. Thus, our\n",
      "theory guarantees the universality of this construction with T = 5 PPGN iterations and a single Convolution iteration, and\n",
      "dimensionality of 12n + 1 neurons for the size of the vector c(i, j). In practice, we use T = 2 PPGN iterations and 4\n",
      "Convolutions.\n",
      "B.2. N-Body Experiment\n",
      "The N-body problem is a physical dynamics problem that arises in a number of physical settings, such as the solar system,\n",
      "electrical charge configurations and double-spring pendulums, in which a model aims to predict the trajectory of objects\n",
      "that mutually assert forces on one another based on a physical law, e.g. gravity in the solar system. The contemporary\n",
      "standard benchmark is a dynamical system in 3D space that models the time-dependent trajectory of 5 particles with an\n",
      "electrical charge. This task has been introduced in (Fuchs et al., 2020), and (Victor Garcia Satorras, 2021) extended the\n",
      "    answer this question: what is the MSE of SE(3) TRASFORMER in the N-body dynamics prediction task?\n",
      "This context does not mention anything about the MSE of SE(3) TRASFORMER in the N-body dynamics prediction task, so I cannot answer this question from the provided context.\n",
      "What process is involved in the stage 2 of developing a multimodal deep learning framework for healthcare?\n",
      "Based on this content: applications that better represent the clinicianâ€™s approach. Here, we provide a review of multimodal\n",
      "machine learning approaches in healthcare, offering a comprehensive overview of recent literature.\n",
      "We discuss the various data modalities used in clinical diagnosis, with a particular emphasis on\n",
      "imaging data. We evaluate fusion techniques, explore existing multimodal datasets and examine\n",
      "common training strategies.\n",
      "Keywords data fusion Â· healthcare Â· multimodal machine learning Â· deep learning\n",
      "1\n",
      "Introduction\n",
      "Artificial Intelligence (AI), and machine learning in particular, has radically altered our interactions with the world,\n",
      "fostering rapid advancements in various domains. However, the adoption of machine learning approaches in healthcare\n",
      "has been slower than in other fields despite the increasing pressure on healthcare systems and the urgent demand for\n",
      "high quality, personalised care [121, 196].\n",
      "\n",
      "---\n",
      "\n",
      "applications that better represent the clinicianâ€™s approach. Here, we provide a review of multimodal\n",
      "machine learning approaches in healthcare, offering a comprehensive overview of recent literature.\n",
      "We discuss the various data modalities used in clinical diagnosis, with a particular emphasis on\n",
      "imaging data. We evaluate fusion techniques, explore existing multimodal datasets and examine\n",
      "common training strategies.\n",
      "Keywords data fusion Â· healthcare Â· multimodal machine learning Â· deep learning\n",
      "1\n",
      "Introduction\n",
      "Artificial Intelligence (AI), and machine learning in particular, has radically altered our interactions with the world,\n",
      "fostering rapid advancements in various domains. However, the adoption of machine learning approaches in healthcare\n",
      "has been slower than in other fields despite the increasing pressure on healthcare systems and the urgent demand for\n",
      "high quality, personalised care [121, 196].\n",
      "\n",
      "---\n",
      "\n",
      "physicians to contextualise their assessments of medical images within the broader clinical picture. In response to this,\n",
      "an increasing volume of AI research in healthcare has focused on the use of multimodal data, aiming to better emulate\n",
      "cliniciansâ€™ approaches and enhance overall performance [185].\n",
      "Many studies have explored the application of machine learning to healthcare and medicine, investigating in particular\n",
      "the development of deep learning techniques across various modalities. These investigations have encompassed a\n",
      "broad range of topics, including general applications [155, 178, 70, 6, 228, 72], those placing particular emphasis on\n",
      "image-based approaches [180, 135, 208] and a specific focus on the chest region [28, 126, 9, 39]. In the context of\n",
      "arXiv:2402.02460v2  [cs.LG]  12 Feb 2024\n",
      "Review of multimodal machine learning approaches in healthcare\n",
      "A PREPRINT\n",
      "Information\n",
      "sources\n",
      "Data\n",
      "modalities\n",
      "Multimodal\n",
      "model\n",
      "Patient mortality \n",
      "predictions\n",
      "Hospitalisation \n",
      "predictions\n",
      "\n",
      "---\n",
      "\n",
      "physicians to contextualise their assessments of medical images within the broader clinical picture. In response to this,\n",
      "an increasing volume of AI research in healthcare has focused on the use of multimodal data, aiming to better emulate\n",
      "cliniciansâ€™ approaches and enhance overall performance [185].\n",
      "Many studies have explored the application of machine learning to healthcare and medicine, investigating in particular\n",
      "the development of deep learning techniques across various modalities. These investigations have encompassed a\n",
      "broad range of topics, including general applications [155, 178, 70, 6, 228, 72], those placing particular emphasis on\n",
      "image-based approaches [180, 135, 208] and a specific focus on the chest region [28, 126, 9, 39]. In the context of\n",
      "arXiv:2402.02460v2  [cs.LG]  12 Feb 2024\n",
      "Review of multimodal machine learning approaches in healthcare\n",
      "A PREPRINT\n",
      "Information\n",
      "sources\n",
      "Data\n",
      "modalities\n",
      "Multimodal\n",
      "model\n",
      "Patient mortality \n",
      "predictions\n",
      "Hospitalisation \n",
      "predictions\n",
      "\n",
      "---\n",
      "\n",
      "What makes the deep learning process unique is the notion of pre-training and fine-tuning [82], which separates the\n",
      "training procedure into two stages. Pre-training a model aims for a model to understand salient concepts in data,\n",
      "which is usually task-agnostic (Section 3.2). Fine-tuning on the other hand transforms these concepts into meaningful\n",
      "information that can be interpreted by humans (Section 3.3).\n",
      "5\n",
      "Review of multimodal machine learning approaches in healthcare\n",
      "A PREPRINT\n",
      "Stage 2:\n",
      "Fine-tuning\n",
      "Stage 1:\n",
      "Pre-training\n",
      "Model:\n",
      "Randomly initialised\n",
      "Model:\n",
      "Fully trained\n",
      "Pre-trained\n",
      "weights\n",
      "Downstream task\n",
      "Fine-\n",
      "tuning \n",
      "dataset\n",
      "Random\n",
      "weights\n",
      "Pretext task\n",
      "Pre-\n",
      "training \n",
      "dataset\n",
      "Figure 2: Model development. After pre-training the model, the model weights are fine-tuned on the target domain\n",
      "(e.g. medical images) and the model architecture is adjusted to the target task (e.g. classification).\n",
      "    answer this question: What process is involved in the stage 2 of developing a multimodal deep learning framework for healthcare?\n",
      "Fine-tuning\n",
      "what is the aim of Model pre-training stage (or representation learning) in context of multimodal machine learning approaches?\n",
      "Based on this content: concepts in the pre-training dataset [96]. This makes it possible to use the learned parameters (weights) from that\n",
      "model for multiple downstream tasks. The literature has shown that if the distribution of the downstream dataset\n",
      "aligns closely with the pre-training dataset, a model pre-trained on medical images is likely to outperform models pre-\n",
      "trained on natural images during fine-tuning, provided the datasets are of comparable size [140]. Unlike pre-training,\n",
      "fine-tuning does not involve pretext tasks and instead is carried out for a specific downstream task that is formulated\n",
      "based on the problem at hand. This usually involves two things: adjusting the model to the target task structure (e.g.\n",
      "for a classification problem, adjusting the last layer of the model); and training the model on the target data, which can\n",
      "either mean training all weights or only weights of specific layers. For multimodal data, modality-specific pre-trained\n",
      "\n",
      "---\n",
      "\n",
      "concepts in the pre-training dataset [96]. This makes it possible to use the learned parameters (weights) from that\n",
      "model for multiple downstream tasks. The literature has shown that if the distribution of the downstream dataset\n",
      "aligns closely with the pre-training dataset, a model pre-trained on medical images is likely to outperform models pre-\n",
      "trained on natural images during fine-tuning, provided the datasets are of comparable size [140]. Unlike pre-training,\n",
      "fine-tuning does not involve pretext tasks and instead is carried out for a specific downstream task that is formulated\n",
      "based on the problem at hand. This usually involves two things: adjusting the model to the target task structure (e.g.\n",
      "for a classification problem, adjusting the last layer of the model); and training the model on the target data, which can\n",
      "either mean training all weights or only weights of specific layers. For multimodal data, modality-specific pre-trained\n",
      "\n",
      "---\n",
      "\n",
      "What makes the deep learning process unique is the notion of pre-training and fine-tuning [82], which separates the\n",
      "training procedure into two stages. Pre-training a model aims for a model to understand salient concepts in data,\n",
      "which is usually task-agnostic (Section 3.2). Fine-tuning on the other hand transforms these concepts into meaningful\n",
      "information that can be interpreted by humans (Section 3.3).\n",
      "5\n",
      "Review of multimodal machine learning approaches in healthcare\n",
      "A PREPRINT\n",
      "Stage 2:\n",
      "Fine-tuning\n",
      "Stage 1:\n",
      "Pre-training\n",
      "Model:\n",
      "Randomly initialised\n",
      "Model:\n",
      "Fully trained\n",
      "Pre-trained\n",
      "weights\n",
      "Downstream task\n",
      "Fine-\n",
      "tuning \n",
      "dataset\n",
      "Random\n",
      "weights\n",
      "Pretext task\n",
      "Pre-\n",
      "training \n",
      "dataset\n",
      "Figure 2: Model development. After pre-training the model, the model weights are fine-tuned on the target domain\n",
      "(e.g. medical images) and the model architecture is adjusted to the target task (e.g. classification).\n",
      "\n",
      "---\n",
      "\n",
      "What makes the deep learning process unique is the notion of pre-training and fine-tuning [82], which separates the\n",
      "training procedure into two stages. Pre-training a model aims for a model to understand salient concepts in data,\n",
      "which is usually task-agnostic (Section 3.2). Fine-tuning on the other hand transforms these concepts into meaningful\n",
      "information that can be interpreted by humans (Section 3.3).\n",
      "5\n",
      "Review of multimodal machine learning approaches in healthcare\n",
      "A PREPRINT\n",
      "Stage 2:\n",
      "Fine-tuning\n",
      "Stage 1:\n",
      "Pre-training\n",
      "Model:\n",
      "Randomly initialised\n",
      "Model:\n",
      "Fully trained\n",
      "Pre-trained\n",
      "weights\n",
      "Downstream task\n",
      "Fine-\n",
      "tuning \n",
      "dataset\n",
      "Random\n",
      "weights\n",
      "Pretext task\n",
      "Pre-\n",
      "training \n",
      "dataset\n",
      "Figure 2: Model development. After pre-training the model, the model weights are fine-tuned on the target domain\n",
      "(e.g. medical images) and the model architecture is adjusted to the target task (e.g. classification).\n",
      "\n",
      "---\n",
      "\n",
      "Supervised pre-training. In supervised learning a model is trained on a large dataset that contains labels and uses\n",
      "the associated label as a supervisory signal [94]. The pretext task in supervised learning is a simple classification or\n",
      "regression task based on the label. A common example is the training of deep networks on ImageNet-1k [57] using\n",
      "the given class labels per data-point to perform a classification task. As the dataset is large, the model will be able to\n",
      "generalise a given class based on the multiple examples the model sees under that class. In a multimodal setting, a\n",
      "signal from a single modality may act as a supervisory signal for another modality from the same data point [163, 48].\n",
      "Supervised pre-training has proven to be strong on very large datasets such as ImageNet-21k [168], mainly due to\n",
      "the generalisation achieved through the exposure to many examples. However, models trained using self-supervised\n",
      "    answer this question: what is the aim of Model pre-training stage (or representation learning) in context of multimodal machine learning approaches?\n",
      "The aim of Model pre-training stage (or representation learning) in the context of multimodal machine learning approaches is to make the model understand salient concepts in data, which is usually task-agnostic. This means that the model is not trained on a specific task, but rather on a general set of tasks that allow it to learn how to represent data in a way that is useful for a variety of downstream tasks.\n",
      "what are the modules of The TopoNetX package?\n",
      "Based on this content: ules: base and nn. The base module implements higher-order message passing methods,\n",
      "allowing the construction of general-purpose TNNs using the tensor diagram formalism in-\n",
      "troduced in Hajij et al. and surveyed in Papillon et al. (2023). The nn module implements\n",
      "various TNNs on popular topological domains, such as simplicial complexes, cell complexes,\n",
      "hypergraphs, and combinatorial complexes. Each implementation includes a correspond-\n",
      "ing Jupyter notebook tutorial for a user-friendly initiation into TDL. TopoModelX leverages\n",
      "PyTorch and PyG (PyTorch Geometric) backends (Fey and Lenssen, 2019). The TopoModelX\n",
      "package is the outcome of a coding challenge that crowd-sourced the implementations of\n",
      "TDL models et al. (2023).\n",
      "3. Comparison and Interaction with Other Packages\n",
      "The libraries most closely related to TopoNetX are NetworkX (Hagberg et al., 2008) and\n",
      "HypernetX (Liu et al., 2021). They facilitate computations on graphs and hypergraphs, re-\n",
      "\n",
      "---\n",
      "\n",
      "spectively. TopoNetX utilizes a similar API to these two libraries to faciliaite rapid adoption\n",
      "of topological domains, such as simplicial complexes, cell complexes, and colored hyper-\n",
      "graphs. The XGI package (Landry et al., 2023) offers hypergraph functionalities similar to\n",
      "HypernetX with additional support for simplicial complexes and directed hypergraphs.\n",
      "The closest package to TopoEmbedX is KarateClub (Rozemberczki et al., 2020), which is\n",
      "a Python package consisting of methods for unsupervised learning on graph-structured data.\n",
      "3\n",
      "Hajij et al.\n",
      ": 0-cell\n",
      "TopoNetX\n",
      "TopoEmbedX\n",
      ": 1-cell\n",
      ": 2-cell\n",
      "TopoModelX\n",
      "Add a cell\n",
      "Embed a cell\n",
      "Build a TNN that passes messages \n",
      "between cells\n",
      "Figure 1: Building blocks from the three packages of the TopoX software suite.\n",
      "Left:\n",
      "TopoNetX enables building topological domains such as cell complexes.\n",
      "The\n",
      "figure demonstrates adding a 2-cell on a cell complex with TopoNetX. Middle:\n",
      "TopoEmbedX enables embedding of topological domains inside a Euclidian space.\n",
      "\n",
      "---\n",
      "\n",
      "topological domains and TDL, enriched by diverse examples, notebooks, and visualization\n",
      "capabilities; and provide a unified application programming interface (API) that operates\n",
      "on topological domains. Given that topological spaces generalize most data domains en-\n",
      "countered in scientific computations, its unified API offers multiple advantages: it enhances\n",
      "interoperability, streamlines productivity, simplifies learning, and fosters collaboration. By\n",
      "providing a common framework, it reduces maintenance, promotes code portability, and\n",
      "supports parallel computing.\n",
      "2. Implementation Overview\n",
      "The TopoNetX package is organized into three main modules: classes, algorithms, and\n",
      "transform. The classes module implements numerous common topological domains, such\n",
      "as SimplicialComplex, CellComplex, and more; inheriting from the abstract class Complex.\n",
      "The algorithms module implements spectral methods, distance computation, and connected\n",
      "\n",
      "---\n",
      "\n",
      "component analysis in topological domains. The transform module facilitates conversions\n",
      "between different topological domains. TopoNetX uses Numpy and Scipy backends, and offers\n",
      "toy datasets and examples to facilitate learning and improve understanding.\n",
      "The TopoEmbedX package supports the learning of representations for all topological do-\n",
      "mains available in TopoNetX. This package contains the module classes, which implements\n",
      "topological representation learning algorithms that generalize the most popular graph-based\n",
      "representation learning algorithms. These algorithms include DeepCell and Cell2Vec. The\n",
      "TopoEmbedX package has an API inspired by scikit-learn (Pedregosa et al., 2011) and\n",
      "utilizes the KarateClub (Rozemberczki et al., 2020) backends.\n",
      "TopoModelX is a Python package for topological deep learning, providing efficient tools\n",
      "to implement topological neural networks (TNNs). The package consists of two main mod-\n",
      "\n",
      "---\n",
      "\n",
      "TopoNetX provides an user-friendly interface which allows to create a complex in two main\n",
      "steps: first, instantiate the complex; second, add cells to that complex, as shown in the three\n",
      "first lines of the code snippet below. Processing data on a complex requires matrices that\n",
      "describe the (co)adjacency of the incidence relations among cells, as computed below.\n",
      "cell_complex = CellComplex ()\n",
      "cell_complex . add_cell ( [ 1 , 2 , 3 , 4 ] ,\n",
      "rank=2)\n",
      "cell_complex . add_cell ( [ 1 , 2 , 5 ] ,\n",
      "rank=2)\n",
      "L2 = cell_complex . hodge_laplacian_matrix (2)\n",
      "The following code snippet shows how TopoEmbedX embeds edges of the Stanford bunny\n",
      "dataset using the Cell2Vec algorithm (Hajij et al., 2020):\n",
      "cell_complex = tnx . datasets . stanford_bunny ( \" c e l l \" )\n",
      "4\n",
      "TopoX: A Suite of Python Packages for Machine Learning on Topological Domains\n",
      "Comparison between TopoNetX and other Python packages\n",
      "Packages\n",
      "Domains\n",
      "Operations\n",
      "TopoNetX\n",
      "Graphs,\n",
      "colored hypergraphs,\n",
      "simplicial\n",
      "    answer this question: what are the modules of The TopoNetX package?\n",
      "The modules of The TopoNetX package are: classes, algorithms, and transform.\n",
      "what's the MAE value of ACRE(R) + Happy Hollow (S)?\n",
      "Based on this content: 7.7\n",
      "ACRE (R)\n",
      "4.33\n",
      "8.7\n",
      "Happy Hollow (S)\n",
      "8.6\n",
      "7.98\n",
      "Happy Hollow (R) + ACRE (S)\n",
      "8.74\n",
      "5.55\n",
      "Happy Hollow (R)\n",
      "9.65\n",
      "5.22\n",
      "ACRE (S)\n",
      "8.74\n",
      "6.59\n",
      "Scenario 2\n",
      "Lindberg\n",
      "ACRE\n",
      "Lindberg (R) + ACRE (S)\n",
      "6.32\n",
      "8.75\n",
      "Lindberg (R)\n",
      "5.39\n",
      "10.49\n",
      "ACRE (S)\n",
      "10.14\n",
      "8.74\n",
      "Scenario 3\n",
      "Lindberg\n",
      "Happy Hollow\n",
      "Lindberg (R) + Happy Hollow (S)\n",
      "9.5\n",
      "7.79\n",
      "Lindberg (R)\n",
      "5.39\n",
      "19.99\n",
      "Happy Hollow (S)\n",
      "10.23\n",
      "7.98\n",
      "Table I: Pathloss prediction accuracy (in MAE) comparing the proposed data augmentation (highlighted) to baselines. â€Râ€\n",
      "denotes real data and â€Sâ€ denotes simulated data. For each dataset, training includes all synthetic data and 50% of the real\n",
      "data, the remaining real data being used for evaluation.\n",
      "B. Generalization Performance Evaluation\n",
      "In Table I, we assess how effectively our proposed train-\n",
      "ing method generalizes across different scenarios, specifically\n",
      "comparing its performance when using only measurement\n",
      "data versus scenarios that use only synthetic datasets. For the\n",
      "\n",
      "---\n",
      "\n",
      "accuracy of ACRE by 1.09 dB, with a minor loss of the\n",
      "prediction accuracy of 0.33 dB for Happy Hollow. A similar\n",
      "trend can be observed in Scenario 2. The proposed data\n",
      "augmentation improved the prediction accuracy for ACRE by\n",
      "2.26 dB at the cost of a 1.07 dB accuracy loss for Lindberg.\n",
      "In Scenario 3, the only real data-based scheme achieves\n",
      "the prediction accuracies of 19.99 dB and 5.38 dB for Happy\n",
      "Hollow and Lindberg, respectively. The large difference in\n",
      "the prediction results for Happy Hollow (hilly) and Lindberg\n",
      "(residential) may suggest that they have significantly different\n",
      "propagation environments. However, when the synthetic data\n",
      "for Happy Hollow was added to the dataset, the prediction\n",
      "accuracy for Happy Hollow was enhanced by approximately\n",
      "12.2 dB. This improvement came with a trade-off, leading to a\n",
      "loss 4.11 dB in the accuracy of the Lindberg prediction, which\n",
      "is consistent with previous findings.\n",
      "These results suggest that the incorporation of synthetic data\n",
      "\n",
      "---\n",
      "\n",
      "MAE of 5.05 dB, a significant improvement over the MAE of\n",
      "8.77 dB observed when the model was trained only using syn-\n",
      "thetic data. Interestingly, the figure also highlights the benefits\n",
      "of our repetitive method compared to using only real data\n",
      "without repetition, which yielded a slightly higher MAE of\n",
      "5.11 dB using 16 repetitions. Similarly, for the Happy Hollow\n",
      "site, the MAE was reduced to 5.67 dB with 20 repetitions,\n",
      "compared to 7.72 dB using only synthetic data and slightly\n",
      "better than 5.74 dB observed with 18 repetitions of only real\n",
      "data. Furthermore, for the Lindberg dataset, where the model\n",
      "reported an MAE of 6.25 dB with 10 repetitions, significantly\n",
      "outperforming the MAE of the synthetic data of 9.87 dB, and\n",
      "also showing a slight advantage over the MAE of 6.32 dB\n",
      "achieved with 10 repetitions of only real data.\n",
      "By addressing data imbalance, we improved the prediction\n",
      "accuracy of our model, even with limited measurements in\n",
      "\n",
      "---\n",
      "\n",
      "Specifically, for the Happy Hollow datasets, excluding the\n",
      "center frequency feature from training and testing improved\n",
      "the modelâ€™s performance over using all features.\n",
      "In general, it can be verified that CatBoost outperforms the\n",
      "other ML schemes and empirical models. The MAE achieved\n",
      "for the ACRE, Happy Hollow, and Lindberg data sets was\n",
      "approximately 8.76 dB, 8.02 dB, and 9.88 dB, respectively. It\n",
      "should be noted that synthetic data, coupled with the developed\n",
      "features, contributed significantly to favorable results. This is\n",
      "evidenced by consistently lower MAE values, which signifi-\n",
      "cantly undercut those obtained with empirical models. For the\n",
      "Happy Hollow dataset, the COST-231 Hata model achieved an\n",
      "MAE of 6.8 dB, which is marginally better than the 8.02 dB of\n",
      "CatBoost when using synthetic data. However, when CatBoost\n",
      "is trained on real data, specifically with a 50% split, it exhibits\n",
      "superior performance with an MAE reduced to approximately\n",
      "\n",
      "---\n",
      "\n",
      "measurement data at each location, we partitioned the dataset\n",
      "into two equal halves, allocating 50% for training purposes\n",
      "and the remaining 50% for testing. Generally, cases that use\n",
      "only measurement data show good prediction accuracy in\n",
      "known areas; however, their performance decreases in unseen\n",
      "areas. In all scenarios, the cases that used only measurement\n",
      "data showed lower performance compared to those that only\n",
      "used simulation data to predict unseen areas. It can be seen\n",
      "that the proposed training method improved the accuracy\n",
      "of the prediction of unseen areas by incorporating synthetic\n",
      "data, although at the cost of some accuracy in known areas.\n",
      "Specifically, the ACRE (R) + Happy Hollow (S) case improved\n",
      "the prediction accuracy of Happy Hollow by 1.0 dB compared\n",
      "to the ACRE (R) case. On the other hand, the accuracy of the\n",
      "ACRE prediction decreased slightly by 0.64 dB. Similarly, the\n",
      "Happy Hollow (R) + ACRE (S) case improved the prediction\n",
      "    answer this question: what's the MAE value of ACRE(R) + Happy Hollow (S)?\n",
      "8.74 dB\n",
      "What's the LPPD of MO-GPLVM in spectroscopy in Regression?\n",
      "Based on this content: the observations both shift in wavelength and change in\n",
      "height with changing latent variables. We fit this data with\n",
      "an MO-GPLVM model with five latent dimensions, but only\n",
      "one was relevant. From the data set illustrated in Figure\n",
      "2(a), we approximated the posterior for the pure signals\n",
      "(sc(Â·, Â·)), latent variables (x) and unobserved mixture com-\n",
      "ponents (râˆ—). The Figure 2(b) results demonstrate that our\n",
      "MO-GPLVM framework can effectively learn the values of\n",
      "all of the unobserved variables when our assumptions hold.\n",
      "4.2. Examples on Data Sets from the Literature\n",
      "For the real-world examples, we compare to standard GP\n",
      "regression and classification and Partial Least Squares (PLS).\n",
      "PLS, a type of linear model, is the industry standard in\n",
      "spectroscopy (Wold et al., 2001; Barker & Rayens, 2003).\n",
      "Since many of the measurements in spectroscopy are with\n",
      "respect to wavelength, they are high dimensional and a\n",
      "6\n",
      "Mixed-Output Gaussian Process Latent Variable Models\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "1000\n",
      "wavelength\n",
      "\n",
      "---\n",
      "\n",
      "need for further work on the optimization of these systems.\n",
      "In these examples, MO-GPLVM classification was less ef-\n",
      "fective than regression, but there are compelling reasons\n",
      "to study classification further. Previous GPLVM work for\n",
      "separates classes within the same latent space (Urtasun &\n",
      "Darrell, 2007). As GPs typically model smooth mappings\n",
      "(JÃ¸rgensen & Hauberg, 2021), it implies that there is some\n",
      "function which smoothly transforms from one class to the\n",
      "other. For many classification problems this is nonsensical\n",
      "as data may only exist in only one class or another. An\n",
      "attractive feature for MO-GPLVM is that it does not as-\n",
      "sume any connection between separate classes, but further\n",
      "development on the MO-GPLVM optimization is required.\n",
      "5. Discussion\n",
      "This paper extends GPLVMs from the output of a single\n",
      "GP to the case where we observe the sum of several GPs\n",
      "in different mixture fractions. This framework is highly\n",
      "applicable to spectroscopic data where the summation in Eq.\n",
      "\n",
      "---\n",
      "\n",
      "2Department of Mathematics, Imperial College London, Lon-\n",
      "don,\n",
      "SW7 2AZ, UK. Correspondence to:\n",
      "Sarah Filippi\n",
      "<s.filippi@imperial.ac.uk>.\n",
      "Copyright 2024 by the author(s).\n",
      "dij\n",
      "ric\n",
      "xi\n",
      "sijc\n",
      "Î»j\n",
      "c = 1, ..., C\n",
      "i = 1, ..., N\n",
      "j = 1, ..., M\n",
      "Figure 1. Bayesian diagram for mixed-output Gaussian Process\n",
      "latent variable models (MO-GPLVM) with unobserved mixture\n",
      "weights ric.\n",
      "As motivation, spectroscopy seeks to identify the abun-\n",
      "dances of different chemical species {c = 1, . . . , C} in\n",
      "a particular sample i. Each of the chemical species has a\n",
      "specific pure component signal, sc, varying across different\n",
      "wavelengths {Î»j}M\n",
      "j=1. The measured signal dij for sample i\n",
      "at wavelength Î»j is the weighted sum of the pure component\n",
      "signals, where the weights (ric) correspond to the chemical\n",
      "abundances present in sample i. However, the pure com-\n",
      "ponent signals in a given sample not only depend on the\n",
      "wavelength but also on other factors, such as temperature or\n",
      "\n",
      "---\n",
      "\n",
      "et al., 2023), so we do not report LPPD or LPP for PLS.\n",
      "Near Infra Red Spectroscopy with Varying Tempera-\n",
      "tures. This data set, from the chemometrics literature, ex-\n",
      "plores the effects of changes in temperature on spectroscopic\n",
      "data (WÂ¨ulfert et al., 1998). The spectroscopic data, shown in\n",
      "Figure 3, consists of a mixture of three components: water,\n",
      "ethanol and 2-propanol. These components were mixed in\n",
      "22 different ratios, including pure components for each of\n",
      "them. Measurements were taken at 5 temperatures between\n",
      "30â—¦C and 70â—¦C. The data was pre-processed as described\n",
      "in Section 3 and randomly split into a training and a test\n",
      "data set, with 50% of the observations used for training and\n",
      "the remaining for testing, shown in Figure 3(a).\n",
      "For our comparison methods, the number of latent dimen-\n",
      "sions for PLS was selected based on 5-fold cross validation\n",
      "on the training data. The threshold for the captured variance\n",
      "of the PCA used prior to the GP was 99.99% of the total,\n",
      "\n",
      "---\n",
      "\n",
      "Predicted Probability (LPP) and the Accuracy (Acc.). Each example was run 10 times and the mean is quoted here, along with two times\n",
      "the standard error of the mean in brackets. For results that deviate significantly from one, powers of ten were removed from all of the\n",
      "results and where applicable these are shown in square brackets at the top of the column. The best mean for each column is in bold.\n",
      "Regression\n",
      "Classification\n",
      "Spectroscopy\n",
      "Oil Flow\n",
      "Remote Sensing\n",
      "Oil Flow\n",
      "Method\n",
      "LPPD\n",
      "MSE [10âˆ’4]\n",
      "LPPD\n",
      "MSE [10âˆ’4]\n",
      "LPP\n",
      "Acc. [10âˆ’2]\n",
      "LPP\n",
      "Acc. [10âˆ’2]\n",
      "MO-GPLVM\n",
      "576(12)\n",
      "2.28(0.38)\n",
      "7480(210)\n",
      "18.7(15.2)\n",
      "-170(51)\n",
      "73.2(6.9)\n",
      "-171(26)\n",
      "97.5 (0.6)\n",
      "GP\n",
      "217(43)\n",
      "48.3(3.6)\n",
      "7150(620)\n",
      "4.50(1.50)\n",
      "-144(13)\n",
      "24.4(6.4)\n",
      "-36.4(4.5)\n",
      "99.4(0.0)\n",
      "PLS\n",
      "n/a\n",
      "3.49(0.95)\n",
      "n/a\n",
      "3.95(1.25)\n",
      "n/a\n",
      "82.0(0.0)\n",
      "n/a\n",
      "97.8(0.1)\n",
      "that we get from assuming that none of the pure signals\n",
      "vary. Assuming that none of the pure signals vary between\n",
      "observations, the least squares estimate for a static signal is\n",
      "Ë†S = DT R(RT R)âˆ’1.\n",
      "(25)\n",
      "    answer this question: What's the LPPD of MO-GPLVM in spectroscopy in Regression?\n",
      "576(12)\n",
      "What's the accuracy of RadBERT-Roberta -4m-sentence in Anomaly detection across various backbone student models?\n",
      "Based on this content: the anomaly detection accuracy of the S-KD method on RadBERT was recorded at 95.06%. This represents a\n",
      "substantial reduction in error rate, approximately threefold, compared to the D-KD method, which achieved\n",
      "an accuracy of 85.52%. These results underscore the superiority and efficacy of the S-KD technique in this\n",
      "context.\n",
      "4.3\n",
      "Analysis of Potential Cause for S-KD Advancement\n",
      "Sec. 4.2 demonstrates that sentence-level knowledge distillation (S-KD) surpasses document-level\n",
      "knowledge distillation (D-KD) in performance. This section delves into the underlying reasons for this\n",
      "improved performance and presents the following key findings: S-KD exhibits superior capabilities over\n",
      "D-KD in two critical aspects. Firstly, S-KD more accurately identifies documents as abnormal when they\n",
      "contain only a low presence of abnormal sentences, which is a more challenging scenario for anomaly\n",
      "detection. Secondly, S-KD effectively corrects misclassifications where documents are incorrectly identified\n",
      "9\n",
      "Model\n",
      "\n",
      "---\n",
      "\n",
      "This study was performed using the two highest-performing backbone models for AD as identified in Table 2:\n",
      "RadBERT-Roberta and BioMED-Roberta. The results, as depicted in Table 4, demonstrate that incorporating\n",
      "the contrastive setting (Î» = 1) significantly improves accuracy and specificity in AD testing for all student\n",
      "models, compared to the baseline (Î» = 0) which does not include contrastive learning. However, the\n",
      "baseline setting exhibits a higher specificity, a discrepancy we attribute to the training data distribution. As\n",
      "discussed in Sec. 4.1, the training data contains a higher proportion of abnormal sentences and documents\n",
      "compared to normal instances, leading to a baseline bias towards abnormal labels. This results in elevated\n",
      "sensitivity but reduced specificity. The introduction of the contrastive setting helps to counteract this bias,\n",
      "enhancing specificity and thereby improving overall accuracy relative to the baseline. Consequently, we\n",
      "\n",
      "---\n",
      "\n",
      "u represent the sentence-level (the\n",
      "j-th sentenceâ€™s) probability for being abnormal, normal, and uncertain, respectively. Then, the\n",
      "final document-level abnormality probability pa is driven as the highest sentence-level probability\n",
      "(togetherwith its inverse value as normal probability pn) as follows:\n",
      "pa â† max(jâˆˆ{1:Dxte})\n",
      "\u0002\n",
      "gÎ¸âˆ—(ste\n",
      "j ){a}\n",
      "\u0003\n",
      ",\n",
      "(4)\n",
      "pn â† 1 âˆ’ pa.\n",
      "This allows for an abnormal document classification if even one sentence is deemed abnormal.\n",
      "5\n",
      "Model\n",
      "Accuracy\n",
      "Specificity\n",
      "Sensitivity\n",
      "AUC\n",
      "RadBERT-Roberta\n",
      "-4m-document\n",
      "85.52\n",
      "0.858\n",
      "0.84\n",
      "0.901\n",
      "RadBERT-Roberta\n",
      "-4m-sentence\n",
      "95.06\n",
      "(+ 9.54)\n",
      "0.941\n",
      "(+ 0.083)\n",
      "0.952\n",
      "(+ 0.112)\n",
      "0.977\n",
      "(+ 0.076)\n",
      "BioMed-Roberta\n",
      "-document\n",
      "86.12\n",
      "0.82\n",
      "0.869\n",
      "0.877\n",
      "BioMed-Roberta\n",
      "-sentence\n",
      "94.6\n",
      "(+ 8.48)\n",
      "0.947\n",
      "(+ 0.127)\n",
      "0.943\n",
      "(+ 0.074)\n",
      "0.979\n",
      "(+ 0.102)\n",
      "BlueBERT\n",
      "-document\n",
      "91.17\n",
      "0.91\n",
      "0.922\n",
      "0.958\n",
      "BlueBERT\n",
      "-sentence\n",
      "93.43\n",
      "(+ 2.26)\n",
      "0.933\n",
      "(+ 0.023)\n",
      "0.945\n",
      "(+ 0.023)\n",
      "0.98\n",
      "(+ 0.022)\n",
      "Clinical BERT\n",
      "-document\n",
      "90.15\n",
      "0.888\n",
      "0.961\n",
      "0.968\n",
      "Clinical BERT\n",
      "-sentence\n",
      "93.07\n",
      "(+ 2.92)\n",
      "0.922\n",
      "\n",
      "---\n",
      "\n",
      "execute three independent label extractions (normal, abnormal, uncertain) for each sentence from GPT-3.5. If\n",
      "these labels exhibit consistency across extractions, we accept them; otherwise, we reject them. Comprehensive\n",
      "details are presented in Appendix.\n",
      "5.2\n",
      "Model Deployment and Implication\n",
      "Our RadBERT-Roberta model, which was trained using sentence-level knowledge distillation (S-KD)\n",
      "with a contrastive setup, has been deployed and is accessible via HuggingFace.\n",
      "Fig. 6 illustrates the modelâ€™s functionality. When a clinician uploads a radiology report, the model\n",
      "highlights sentences indicative of normal and abnormal findings in green and purple, respectively, while\n",
      "sentences deemed uncertain are marked in gray. This feature enables radiologists or doctors to review reports\n",
      "more efficiently by focusing primarily on the text highlighted in green and purple, thereby potentially omitting\n",
      "the gray-marked uncertain content.\n",
      "5.3\n",
      "Limitation\n",
      "\n",
      "---\n",
      "\n",
      "sentences (51,568 normal, 64,715 abnormal, and 55,822 uncertain) and 40,779 testing sentences (12,105\n",
      "normal, 15,655 abnormal, and 13,019 uncertain). Baseline D-KD training uses the document-level dataset,\n",
      "whereas our S-KD training employs the associated sentence-level dataset for a fair comparison. Other details\n",
      "are in Appendix.\n",
      "4.2\n",
      "Performance Comparison between Proposed and Baseline KD Approach\n",
      "In this section, we present a comparative analysis of the test performances of two knowledge distillation\n",
      "(KD) methods as outlined in Sec. 3: document-level KD (D-KD) and sentence-level KD (S-KD). These\n",
      "methodologies were applied to six medically specialized BERT (Bidirectional Encoder Representations from\n",
      "Transformers)-based backbone models as for KD student models. The models assessed under KD training\n",
      "are RadBERT-Roberta [16], BioMed-Roberta [20], BioBERT [21], ClinicalBERT [22], BiomedBERT [23],\n",
      "8\n",
      "    answer this question: What's the accuracy of RadBERT-Roberta -4m-sentence in Anomaly detection across various backbone student models?\n",
      "95.06%\n",
      "Who are the authors of Knowledge Editing on Black-box Large Language Models?\n",
      "Based on this content: Knowledge Editing on Black-box Large Language Models\n",
      "Xiaoshuai Song1âˆ—, Zhengyang Wang1âˆ—, Keqing He2, Guanting Dong1, Yutao Mou1\n",
      "Jinxu Zhao1, Weiran Xu1*\n",
      "1Beijing University of Posts and Telecommunications, Beijing, China\n",
      "2Meituan, Beijing, China\n",
      "{songxiaoshuai,wzyang,dongguanting,myt,zhaojinxu,xuweiran}@bupt.edu.cn\n",
      "hekeqing@meituan.com\n",
      "Abstract\n",
      "Knowledge editing (KE) aims to efficiently and\n",
      "precisely modify the behavior of large language\n",
      "models (LLMs) to update specific knowledge\n",
      "without negatively influencing other knowl-\n",
      "edge. Current research primarily focuses on\n",
      "white-box LLMs editing, overlooking an impor-\n",
      "tant scenario: black-box LLMs editing, where\n",
      "LLMs are accessed through interfaces and only\n",
      "textual output is available. In this paper, we first\n",
      "officially introduce KE on black-box LLMs\n",
      "and then propose a comprehensive evaluation\n",
      "framework to overcome the limitations of ex-\n",
      "isting evaluations that are not applicable to\n",
      "black-box LLMs editing and lack comprehen-\n",
      "\n",
      "---\n",
      "\n",
      "relevance is constantly emerging. Frequent fine-\n",
      "tuning is impractical due to intensive computational\n",
      "* The first two authors contribute equally. Weiran Xu is\n",
      "the corresponding author.\n",
      "1We\n",
      "release\n",
      "our\n",
      "code\n",
      "at\n",
      "https://github.com/\n",
      "songxiaoshuai/postEdit.\n",
      "Who is the president of the US? \n",
      "Joe Biden is the current\n",
      "President of the US. \n",
      "Donald Trump is the current\n",
      "President of the US. \n",
      "Knowledge Editing: <President of the US, is, Donald Trumpâ†’Joe Biden>\n",
      "Who is the president of the US? \n",
      "(a)  An example of knowledege editing for fixing and updating LLMs. \n",
      "â€¦\n",
      "â€¦\n",
      "(b) Editing of open-source white box LLMs (c) Editing of closed-source black box LLMs\n",
      "Figure 1: Illustration of Knowledge Editing and compar-\n",
      "ison of two editing scenarios, where black-box LLMs\n",
      "editing constrains LLMs to only obtain textual output.\n",
      "overload and the catastrophic forgetting caused by\n",
      "overfitting to new data (Feng et al., 2023; Wang\n",
      "et al., 2023b). To address this issue, the concept of\n",
      "\n",
      "---\n",
      "\n",
      "ditionally, due to the difficulty in obtaining contin-\n",
      "uously up-to-date knowledge, some KE datasets\n",
      "such as CounterFact use counterfactual knowledge\n",
      "to validate the effectiveness of methods. Further-\n",
      "more, the base LLM, such as ChatGPT used in this\n",
      "work, merely serves as a demonstration of research\n",
      "on knowledge editing in black-box model scenar-\n",
      "ios. We emphasize that these datasets and LLMs\n",
      "are solely for academic exploration and do not in-\n",
      "volve actual applications in real-world scenarios,\n",
      "nor do they include content modification or attacks\n",
      "on commercially used LLMs.\n",
      "References\n",
      "Ning Bian, Xianpei Han, Le Sun, Hongyu Lin, Yaojie\n",
      "Lu, and Ben He. 2023. Chatgpt is a knowledgeable\n",
      "but inexperienced solver: An investigation of com-\n",
      "monsense problem in large language models. arXiv\n",
      "preprint arXiv:2303.16421.\n",
      "Meng Cao, Yue Dong, Jiapeng Wu, and Jackie Chi Kit\n",
      "Cheung. 2020. Factual error correction for abstrac-\n",
      "tive summarization models. In Proceedings of the\n",
      "\n",
      "---\n",
      "\n",
      "C.2\n",
      "Details of Baselines\n",
      "â€¢ IKE (Zheng et al., 2023) is a method of knowl-\n",
      "edge editing that does not involve modifying\n",
      "the parameters of LLMs. It defines three types\n",
      "of demonstration formatting templates includ-\n",
      "ing copy, update, and retain. These templates\n",
      "serve distinct functions and act as guiding\n",
      "principles for the language model, enabling\n",
      "it to edit knowledge through in-context learn-\n",
      "ing, allowing IKE to maintain both efficiency\n",
      "and excellent generalization and specificity.\n",
      "This opens up the possibility of employing\n",
      "IKE for the task of knowledge editing even in\n",
      "scenarios involving black-box models.\n",
      "â€¢ PROMPT (Zheng et al., 2023) is similar\n",
      "to IKE, as a method of knowledge editing\n",
      "through in-context learning. However, unlike\n",
      "IKE, PROMPT doesnâ€™t require constructing\n",
      "three types of demonstrations but directly pro-\n",
      "vides new knowledge to the LLM for knowl-\n",
      "edge editing.\n",
      "â€¢ SERAC (Mitchell et al., 2022) is a memory-\n",
      "based method of knowledge editing. This\n",
      "\n",
      "---\n",
      "\n",
      "expert model called post-editor, guided by editing\n",
      "knowledge, makes fine-grained modifications to\n",
      "original responses generated by LLM, thereby ef-\n",
      "fectively preserving the original style. As the role\n",
      "of post-editor is to discern and precisely edit the\n",
      "original response rather than storing new knowl-\n",
      "edge, we integrate editing memory and a retriever\n",
      "into postEdit, like IKE and SERAC, for efficient\n",
      "knowledge injection. We leave the detailed exposi-\n",
      "tion in Section 3. Finally, we conduct comprehen-\n",
      "sive experiments and analysis to demonstrate that\n",
      "postEdit achieves outstanding performance in both\n",
      "editing and style retention, exhibiting robust gener-\n",
      "alization across various aspects, including LLMs,\n",
      "data, and scales in Section 4 and 5.\n",
      "Our contributions are three-fold: (1) We offi-\n",
      "cially introduce knowledge editing on black-box\n",
      "LLMs and propose a comprehensive KE evalua-\n",
      "tion framework, incorporating the assessment of\n",
      "style retention for the first time. (2) We propose\n",
      "    answer this question: Who are the authors of Knowledge Editing on Black-box Large Language Models?\n",
      "Xiaoshuai Song, Zhengyang Wang, Keqing He, Guanting Dong, Yutao Mou, Jinxu Zhao, and Weiran Xu\n",
      "Who are the authors of Towards Robust Model-Based Reinforcement Learning\n",
      "Against Adversarial Corruption?\n",
      "Based on this content: contribute theoretical insights to address practical challenges in model-based RL, particularly in\n",
      "the face of adversarial corruption.\n",
      "Several future work are worth exploring: (1) Extending the uncertainty weighting technique to\n",
      "representation learning problems in RL (Jiang et al., 2017; Liu et al., 2022) would be an intriguing\n",
      "direction; and (2) In situations where the corruption level C is unknown, our method relies on an\n",
      "optimistic estimation of corruption denoted by Â¯C. There is a need for further investigation into\n",
      "the applicability of the model selection technique introduced by Wei et al. (2022) to the realm of\n",
      "model-based RL.\n",
      "7\n",
      "Impact Statements\n",
      "This paper introduces research aimed at enhancing the resilience of model-based reinforcement\n",
      "learning (RL) when confronted with adversarial corruption and malicious attacks. The enhanced\n",
      "robustness achieved by this work not only enhances the reliability of RL systems but also contributes\n",
      "\n",
      "---\n",
      "\n",
      "arXiv:2402.08991v2  [stat.ML]  15 Feb 2024\n",
      "Towards Robust Model-Based Reinforcement Learning\n",
      "Against Adversarial Corruption\n",
      "Chenlu Yeâˆ—â€ \n",
      "Jiafan Heâˆ—â€¡\n",
      "Quanquan GuÂ§\n",
      "Tong ZhangÂ¶\n",
      "Abstract\n",
      "This study tackles the challenges of adversarial corruption in model-based reinforcement\n",
      "learning (RL), where the transition dynamics can be corrupted by an adversary. Existing studies\n",
      "on corruption-robust RL mostly focus on the setting of model-free RL, where robust least-\n",
      "square regression is often employed for value function estimation. However, these techniques\n",
      "cannot be directly applied to model-based RL. In this paper, we focus on model-based RL and\n",
      "take the maximum likelihood estimation (MLE) approach to learn transition model. Our work\n",
      "encompasses both online and oï¬„ine settings. In the online setting, we introduce an algorithm\n",
      "called corruption-robust optimistic MLE (CR-OMLE), which leverages total-variation (TV)-\n",
      "\n",
      "---\n",
      "\n",
      "Ye, C., Yang, R., Gu, Q., and Zhang, T. (2023b). Corruption-robust oï¬„ine reinforcement learning\n",
      "with general function approximation. arXiv preprint arXiv:2310.14550.\n",
      "Zhang, T. (2023). Mathematical analysis of machine learning algorithms. Cambridge University\n",
      "Press.\n",
      "Zhang, X., Chen, Y., Zhu, X., and Sun, W. (2022). Corruption-robust oï¬„ine reinforcement learning.\n",
      "In International Conference on Artiï¬cial Intelligence and Statistics, pages 5757â€“5773. PMLR.\n",
      "Zhao, H., He, J., and Gu, Q. (2023). A nearly optimal and low-switching algorithm for reinforcement\n",
      "learning with general function approximation. arXiv preprint arXiv:2311.15238.\n",
      "Zhao, H., Zhou, D., and Gu, Q. (2021). Linear contextual bandits with adversarial corruptions.\n",
      "arXiv preprint arXiv:2110.12615.\n",
      "Zhong, H., Xiong, W., Tan, J., Wang, L., Zhang, T., Wang, Z., and Yang, Z. (2022a). Pessimistic\n",
      "minimax value iteration: Provably eï¬ƒcient equilibrium learning from oï¬„ine datasets. In Inter-\n",
      "\n",
      "---\n",
      "\n",
      "and transitions, the environments in real-world scenarios are often non-stationary and vulnerable\n",
      "to adversarial corruptions.\n",
      "For instance, autonomous vehicles frequently fall victim to misled\n",
      "navigation caused by hacked maps and adversarially contaminated traï¬ƒc signs (Eykholt et al.,\n",
      "2018).\n",
      "Similarly, in smart healthcare systems, an adversary with partial knowledge can easily\n",
      "manipulate patient statuses (Newaz et al., 2020). Under this situation, standard RL algorithms\n",
      "often fail to ï¬nd policies robust to such adversarial corruption. Therefore, how to identify the\n",
      "optimal policies against the adversarial corruption has witnessed a ï¬‚urry of recent investigations.\n",
      "âˆ—The ï¬rst two authors contributed equally.\n",
      "â€ The Hong Kong University of Science and Technology. Email: cyeab@connect.ust.hk\n",
      "â€¡University of California, Los Angeles. Email: jiafanhe19@ucla.edu\n",
      "Â§University of California, Los Angeles. Email: qgu@cs.ucla.edu\n",
      "\n",
      "---\n",
      "\n",
      "corruption and its application to block mdp. In International Conference on Machine Learning,\n",
      "pages 11296â€“11306. PMLR.\n",
      "Xie, T., Cheng, C.-A., Jiang, N., Mineiro, P., and Agarwal, A. (2021). Bellman-consistent pessimism\n",
      "for oï¬„ine reinforcement learning. Advances in neural information processing systems, 34:6683â€“\n",
      "6694.\n",
      "Xiong, W., Zhong, H., Shi, C., Shen, C., Wang, L., and Zhang, T. (2022). Nearly minimax optimal\n",
      "oï¬„ine reinforcement learning with linear function approximation: Single-agent mdp and markov\n",
      "game. arXiv preprint arXiv:2205.15512.\n",
      "Yang, L. and Wang, M. (2020). Reinforcement learning in feature space: Matrix bandit, kernels,\n",
      "and regret bound. In International Conference on Machine Learning, pages 10746â€“10756. PMLR.\n",
      "Ye, C., Xiong, W., Gu, Q., and Zhang, T. (2023a). Corruption-robust algorithms with uncertainty\n",
      "weighting for nonlinear contextual bandits and markov decision processes. In International Con-\n",
      "ference on Machine Learning, pages 39834â€“39863. PMLR.\n",
      "17\n",
      "    answer this question: Who are the authors of Towards Robust Model-Based Reinforcement Learning\n",
      "Against Adversarial Corruption?\n",
      "The authors of Towards Robust Model-Based Reinforcement Learning Against Adversarial Corruption are Chenlu Ye, Jiafan He, Quanquan Gu, and Tong Zhang.\n",
      "What is the maximum number of steps in Cart Pole in figure 2?\n",
      "Based on this content: [â€™Hâ€™: 15.79, â€™Bâ€™: 2.63, â€™Eâ€™: 31.58, â€™Gâ€™: 7.89, â€™Iâ€™: 0.0, â€™Tâ€™:\n",
      "15.79, â€™Sâ€™: 5.26, â€™Pâ€™: 5.26, â€™-â€™: 15.79]\n",
      "[0.7722, 1.0376, 1.5225, 1.6534, 2.5441, 2.9513, 3.2873,\n",
      "3.7214, 4.1792, 4.3437, 4.3908, 4.6551, 5.1631]\n",
      "3.10.20.90\n",
      "1nct\n",
      "106\n",
      "[â€™Hâ€™: 0.0, â€™Bâ€™: 4.08, â€™Eâ€™: 35.71, â€™Gâ€™: 0.0, â€™Iâ€™: 0.0, â€™Tâ€™: 2.04,\n",
      "â€™Sâ€™: 21.43, â€™Pâ€™: 0.0, â€™-â€™: 36.73]\n",
      "[3.6644, 4.425, 6.5351, 6.7432, 7.1409, 7.1986, 9.0207,\n",
      "9.2223, 10.3163, 10.7313, 11.5299, 11.6373, 12.5606]\n",
      "2.60.40.10\n",
      "1tit\n",
      "98\n",
      "[â€™Hâ€™: 0.0, â€™Bâ€™: 1.12, â€™Eâ€™: 35.96, â€™Gâ€™: 0.0, â€™Iâ€™: 0.0, â€™Tâ€™: 6.74,\n",
      "â€™Sâ€™: 17.98, â€™Pâ€™: 0.0, â€™-â€™: 38.2]\n",
      "[5.5288, 5.9092, 8.2775, 8.6267, 9.3391, 9.8783, 10.1607,\n",
      "11.451, 11.5896, 11.7052, 12.1498, 12.6082, 13.8622]\n",
      "2.60.40.10\n",
      "1qjo\n",
      "80\n",
      "[â€™Hâ€™: 0.0, â€™Bâ€™: 2.5, â€™Eâ€™: 40.0, â€™Gâ€™: 0.0, â€™Iâ€™: 0.0, â€™Tâ€™: 8.75,\n",
      "â€™Sâ€™: 13.75, â€™Pâ€™: 0.0, â€™-â€™: 35.0]\n",
      "[3.8578, 4.4398, 5.4886, 5.7815, 6.6332, 6.9269, 7.2329,\n",
      "7.6453, 8.2545, 8.3076, 8.6118, 8.7135, 8.8546]\n",
      "2.40.50.100\n",
      "2ptl\n",
      "78\n",
      "[â€™Hâ€™: 15.38, â€™Bâ€™: 1.28, â€™Eâ€™: 30.77, â€™Gâ€™: 0.0, â€™Iâ€™: 0.0, â€™Tâ€™:\n",
      "\n",
      "---\n",
      "\n",
      "46.6666666666,\n",
      "â€™Gâ€™:\n",
      "0.0,\n",
      "â€™Iâ€™:\n",
      "0.0,\n",
      "â€™Tâ€™:\n",
      "14.1666666666, â€™Sâ€™: 7.5, â€™Pâ€™:\n",
      "0.0, â€™-â€™: 18.33333333333\n",
      "[2.0337,\n",
      "2.8678,\n",
      "3.3843,\n",
      "3.6263,\n",
      "3.9904,\n",
      "4.5381,\n",
      "4.8373,\n",
      "4.8956,\n",
      "5.1492,\n",
      "5.4416]\n",
      "â€™Hâ€™: 15.8333333333, â€™Bâ€™: 0.0,\n",
      "â€™Eâ€™: 46.666666666, â€™Gâ€™: 2.5,\n",
      "â€™Iâ€™: 0.0, â€™Tâ€™: 14.1666666666,\n",
      "â€™Sâ€™: 4.1666666666, â€™Pâ€™: 0.0, â€™-\n",
      "â€™: 16.666666666\n",
      "[1.8739,\n",
      "2.1563,\n",
      "2.7611,\n",
      "3.1086,\n",
      "3.8712,\n",
      "4.0481,\n",
      "4.3759,\n",
      "4.6717,\n",
      "4.8183,\n",
      "4.9126]\n",
      "2\n",
      "GSPLPRPPLSPEEQEALR\n",
      "KKAQEKYNEFVSKIKEL\n",
      "LRRAADRVRRGEPVELIE\n",
      "KTIKIGDYEYKIVATSPEE\n",
      "AKELENLIKEMIDLGFKP\n",
      "SKEFSDKLVEAARLIREG\n",
      "RVDEALRLLDEM\n",
      "â€™Hâ€™:\n",
      "61.666666666,\n",
      "â€™Bâ€™:\n",
      "0.0,\n",
      "â€™Eâ€™:\n",
      "11.6666666666,\n",
      "â€™Gâ€™: 0.0, â€™Iâ€™: 0.0, â€™Tâ€™: 7.5,\n",
      "â€™Sâ€™:\n",
      "3.33333333333,\n",
      "â€™Pâ€™:\n",
      "3.33333333333, â€™-â€™: 12.5\n",
      "[0.0207,\n",
      "0.1058,\n",
      "0.1782,\n",
      "0.4189, 0.49, 0.9015, 1.1832,\n",
      "1.8257, 2.1212, 2.8726]\n",
      "â€™Hâ€™: 62.5,\n",
      "â€™Bâ€™: 0.0,\n",
      "â€™Eâ€™:\n",
      "11.6666666666, â€™Gâ€™: 0.0, â€™Iâ€™:\n",
      "0.0,\n",
      "â€™Tâ€™:\n",
      "6.6666666666,\n",
      "â€™Sâ€™:\n",
      "1.66666666666,\n",
      "â€™Pâ€™:\n",
      "4.1666666666,\n",
      "â€™-â€™:\n",
      "13.3333333333\n",
      "[0.0444,\n",
      "0.1641,\n",
      "0.3379,\n",
      "0.5724,\n",
      "0.765,\n",
      "0.9568,\n",
      "1.4306,\n",
      "1.5344,\n",
      "1.6834,\n",
      "1.8099]\n",
      "3\n",
      "APLDPDDLSAQLRAAIDE\n",
      "LVRLGYEEEVSKPEFIEA\n",
      "\n",
      "---\n",
      "\n",
      "LRLYALDLGLKEVVLRR\n",
      "VTPAPASQPGVYTVEDV\n",
      "TVDLEALRKQELSPEEQA\n",
      "RLEKIRAKYDEMLADPE\n",
      "FQALLDEVLARARAA\n",
      "â€™Hâ€™: 57.499999999, â€™Bâ€™: 0.0,\n",
      "â€™Eâ€™:\n",
      "13.3333333333,\n",
      "â€™Gâ€™:\n",
      "0.0,\n",
      "â€™Iâ€™:\n",
      "4.1666666666,\n",
      "â€™Tâ€™:\n",
      "8.3333333333,\n",
      "â€™Sâ€™:\n",
      "3.33333333333,\n",
      "â€™Pâ€™:\n",
      "6.6666666666,\n",
      "â€™-â€™:\n",
      "6.6666666666\n",
      "[0.7546,\n",
      "1.0836,\n",
      "1.5026,\n",
      "1.8874,\n",
      "2.0844,\n",
      "2.3192,\n",
      "2.7975,\n",
      "3.0199,\n",
      "3.0669,\n",
      "3.1382]\n",
      "â€™Hâ€™:\n",
      "61.666666666,\n",
      "â€™Bâ€™:\n",
      "0.0, â€™Eâ€™: 15.0, â€™Gâ€™: 0.0, â€™Iâ€™:\n",
      "0.0,\n",
      "â€™Tâ€™:\n",
      "8.3333333333,\n",
      "â€™Sâ€™:\n",
      "3.33333333333,\n",
      "â€™Pâ€™:\n",
      "1.66666666666, â€™-â€™: 10.0\n",
      "[0.5256,\n",
      "1.0278,\n",
      "1.1566,\n",
      "1.2877,\n",
      "1.5521,\n",
      "1.9111,\n",
      "2.1887,\n",
      "2.4664,\n",
      "2.734,\n",
      "2.8731]\n",
      "Figure 4: Overview of the multi-agent work to solve the complex task posed in experiment III, Section 2.3.\n",
      "First the multi-agent uses Chroma to generate de novo protein sequences and structures conditioned on the input\n",
      "CATH class. Then using the generated protein structures, the natural frequencies and secondary structures content are\n",
      "computed. Next, the force (maximum force along the unfolding force-extension curve) and energy (the area under the\n",
      "\n",
      "---\n",
      "\n",
      "rule, i.e., the criterion used to select a variable for branching, has been identified as having a critical\n",
      "impact on performance [2]. Computational studies have served to identify a number of metrics\n",
      "that are good indicators of how a variable will perform. Notably, state-of-the-art branching rules\n",
      "look at the change in objective value in the resulting children nodes. More specifically, let zLPi\n",
      "be the objective value of the current node i and let zLPi+ and zLPiâˆ’ be the objective values of the\n",
      "two nodes resulting from branching on candidate variable xk. This variable will be scored using a\n",
      "combination7 of âˆ†+ := zLPi+ âˆ’ zLPi and âˆ†âˆ’ := zLPiâˆ’ âˆ’ zLPi. These values can be explicitly\n",
      "calculated for each candidate at the moment of branching (thus solving two LPs per candidate).\n",
      "Such strategy, known as strong branching, was introduced in the context of the travelling salesman\n",
      "problem [7] and later standardised by CPLEX.\n",
      "\n",
      "---\n",
      "\n",
      "Dividing (20) by (21) leads to\n",
      "L\n",
      "\u0010(aanti\n",
      "m )âˆ’1 âˆ’ Î»n\n",
      "Î»n + Âµn\n",
      "\u0011âˆ’1/2\n",
      "tan\n",
      "\u0010s\n",
      "(aanti\n",
      "m )âˆ’1 âˆ’ Î»n\n",
      "Î»n + Âµn\n",
      "L\n",
      "\u0011\n",
      "= L(1 + Âµ\n",
      "Î»n\n",
      ") tanh(L).\n",
      "The equation tan(x)/x = ËœC, where ËœC is constant, has exactly one solution in any interval [Ï€(k âˆ’\n",
      "1/2), Ï€(k + 1/2)] for k âˆˆ Z. Therefore, there is only one admissible value of\n",
      "q\n",
      "(aanti\n",
      "m\n",
      ")âˆ’1âˆ’Î»n\n",
      "Î»n+Âµn\n",
      "in\n",
      "each of these interval. So,\n",
      "Î»n + (Î»n + Âµn)(m âˆ’ 1/2)2Ï€2/L2 â©½ (aanti\n",
      "m )âˆ’1 â©½ Î»n + (Î»n + Âµn)(m + 1/2)2Ï€2/L2.\n",
      "51\n",
      "DOUM`ECHE BACH BIAU BOYER\n",
      "Step 5: Conclusion.\n",
      "Recall that the sequence (am)mâˆˆN is a non-increasing re-indexing of the\n",
      "sequences (asym\n",
      "m )mâˆˆN and (aanti\n",
      "m )mâˆˆN. Putting the bounds obtained for asym\n",
      "m\n",
      "and aanti\n",
      "m\n",
      "together, we\n",
      "obtain\n",
      "Î»n + (Î»n + Âµn)(m/2 âˆ’ 1)2Ï€2/L2 â©½ aâˆ’1\n",
      "m â©½ Î»n + (Î»n + Âµn)(m/2 + 1)2Ï€2/L2,\n",
      "and\n",
      "(Î»n + Âµn)(m âˆ’ 2)2Ï€2/(4L2) â©½ aâˆ’1\n",
      "m â©½ (Î»n + Âµn)(m + 4)2Ï€2/(4L2).\n",
      "We conclude that\n",
      "4L2\n",
      "(Î»n + Âµn)(m + 4)2Ï€2 â©½ am â©½\n",
      "4L2\n",
      "(Î»n + Âµn)(m âˆ’ 2)2Ï€2 .\n",
      "F.4. Proof of Proposition 5.3\n",
      "    answer this question: What is the maximum number of steps in Cart Pole in figure 2?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zaiss\\OneDrive - Ecole Centrale Casablanca\\Hackathon\\langchain\\Lib\\site-packages\\langchain_core\\vectorstores.py:331: UserWarning: Relevance scores must be between 0 and 1, got [(Document(page_content='[â€™Hâ€™: 15.79, â€™Bâ€™: 2.63, â€™Eâ€™: 31.58, â€™Gâ€™: 7.89, â€™Iâ€™: 0.0, â€™Tâ€™:\\n15.79, â€™Sâ€™: 5.26, â€™Pâ€™: 5.26, â€™-â€™: 15.79]\\n[0.7722, 1.0376, 1.5225, 1.6534, 2.5441, 2.9513, 3.2873,\\n3.7214, 4.1792, 4.3437, 4.3908, 4.6551, 5.1631]\\n3.10.20.90\\n1nct\\n106\\n[â€™Hâ€™: 0.0, â€™Bâ€™: 4.08, â€™Eâ€™: 35.71, â€™Gâ€™: 0.0, â€™Iâ€™: 0.0, â€™Tâ€™: 2.04,\\nâ€™Sâ€™: 21.43, â€™Pâ€™: 0.0, â€™-â€™: 36.73]\\n[3.6644, 4.425, 6.5351, 6.7432, 7.1409, 7.1986, 9.0207,\\n9.2223, 10.3163, 10.7313, 11.5299, 11.6373, 12.5606]\\n2.60.40.10\\n1tit\\n98\\n[â€™Hâ€™: 0.0, â€™Bâ€™: 1.12, â€™Eâ€™: 35.96, â€™Gâ€™: 0.0, â€™Iâ€™: 0.0, â€™Tâ€™: 6.74,\\nâ€™Sâ€™: 17.98, â€™Pâ€™: 0.0, â€™-â€™: 38.2]\\n[5.5288, 5.9092, 8.2775, 8.6267, 9.3391, 9.8783, 10.1607,\\n11.451, 11.5896, 11.7052, 12.1498, 12.6082, 13.8622]\\n2.60.40.10\\n1qjo\\n80\\n[â€™Hâ€™: 0.0, â€™Bâ€™: 2.5, â€™Eâ€™: 40.0, â€™Gâ€™: 0.0, â€™Iâ€™: 0.0, â€™Tâ€™: 8.75,\\nâ€™Sâ€™: 13.75, â€™Pâ€™: 0.0, â€™-â€™: 35.0]\\n[3.8578, 4.4398, 5.4886, 5.7815, 6.6332, 6.9269, 7.2329,\\n7.6453, 8.2545, 8.3076, 8.6118, 8.7135, 8.8546]\\n2.40.50.100\\n2ptl\\n78\\n[â€™Hâ€™: 15.38, â€™Bâ€™: 1.28, â€™Eâ€™: 30.77, â€™Gâ€™: 0.0, â€™Iâ€™: 0.0, â€™Tâ€™:', metadata={'Authors': 'A. Ghafarollahi, M. J. Buehler', 'Published': '2024-01-27', 'Summary': 'Designing de novo proteins beyond those found in nature holds significant\\npromise for advancements in both scientific and engineering applications.\\nCurrent methodologies for protein design often rely on AI-based models, such as\\nsurrogate models that address end-to-end problems by linking protein structure\\nto material properties or vice versa. However, these models frequently focus on\\nspecific material objectives or structural properties, limiting their\\nflexibility when incorporating out-of-domain knowledge into the design process\\nor comprehensive data analysis is required. In this study, we introduce\\nProtAgents, a platform for de novo protein design based on Large Language\\nModels (LLMs), where multiple AI agents with distinct capabilities\\ncollaboratively address complex tasks within a dynamic environment. The\\nversatility in agent development allows for expertise in diverse domains,\\nincluding knowledge retrieval, protein structure analysis, physics-based\\nsimulations, and results analysis. The dynamic collaboration between agents,\\nempowered by LLMs, provides a versatile approach to tackling protein design and\\nanalysis problems, as demonstrated through diverse examples in this study. The\\nproblems of interest encompass designing new proteins, analyzing protein\\nstructures and obtaining new first-principles data -- natural vibrational\\nfrequencies -- via physics simulations. The concerted effort of the system\\nallows for powerful automated and synergistic design of de novo proteins with\\ntargeted mechanical properties. The flexibility in designing the agents, on one\\nhand, and their capacity in autonomous collaboration through the dynamic\\nLLM-based multi-agent environment on the other hand, unleashes great potentials\\nof LLMs in addressing multi-objective materials problems and opens up new\\navenues for autonomous materials discovery and design.', 'Title': 'ProtAgents: Protein discovery via large language model multi-agent collaborations combining physics and machine learning'}), 0.058271238341068954), (Document(page_content='46.6666666666,\\nâ€™Gâ€™:\\n0.0,\\nâ€™Iâ€™:\\n0.0,\\nâ€™Tâ€™:\\n14.1666666666, â€™Sâ€™: 7.5, â€™Pâ€™:\\n0.0, â€™-â€™: 18.33333333333\\n[2.0337,\\n2.8678,\\n3.3843,\\n3.6263,\\n3.9904,\\n4.5381,\\n4.8373,\\n4.8956,\\n5.1492,\\n5.4416]\\nâ€™Hâ€™: 15.8333333333, â€™Bâ€™: 0.0,\\nâ€™Eâ€™: 46.666666666, â€™Gâ€™: 2.5,\\nâ€™Iâ€™: 0.0, â€™Tâ€™: 14.1666666666,\\nâ€™Sâ€™: 4.1666666666, â€™Pâ€™: 0.0, â€™-\\nâ€™: 16.666666666\\n[1.8739,\\n2.1563,\\n2.7611,\\n3.1086,\\n3.8712,\\n4.0481,\\n4.3759,\\n4.6717,\\n4.8183,\\n4.9126]\\n2\\nGSPLPRPPLSPEEQEALR\\nKKAQEKYNEFVSKIKEL\\nLRRAADRVRRGEPVELIE\\nKTIKIGDYEYKIVATSPEE\\nAKELENLIKEMIDLGFKP\\nSKEFSDKLVEAARLIREG\\nRVDEALRLLDEM\\nâ€™Hâ€™:\\n61.666666666,\\nâ€™Bâ€™:\\n0.0,\\nâ€™Eâ€™:\\n11.6666666666,\\nâ€™Gâ€™: 0.0, â€™Iâ€™: 0.0, â€™Tâ€™: 7.5,\\nâ€™Sâ€™:\\n3.33333333333,\\nâ€™Pâ€™:\\n3.33333333333, â€™-â€™: 12.5\\n[0.0207,\\n0.1058,\\n0.1782,\\n0.4189, 0.49, 0.9015, 1.1832,\\n1.8257, 2.1212, 2.8726]\\nâ€™Hâ€™: 62.5,\\nâ€™Bâ€™: 0.0,\\nâ€™Eâ€™:\\n11.6666666666, â€™Gâ€™: 0.0, â€™Iâ€™:\\n0.0,\\nâ€™Tâ€™:\\n6.6666666666,\\nâ€™Sâ€™:\\n1.66666666666,\\nâ€™Pâ€™:\\n4.1666666666,\\nâ€™-â€™:\\n13.3333333333\\n[0.0444,\\n0.1641,\\n0.3379,\\n0.5724,\\n0.765,\\n0.9568,\\n1.4306,\\n1.5344,\\n1.6834,\\n1.8099]\\n3\\nAPLDPDDLSAQLRAAIDE\\nLVRLGYEEEVSKPEFIEA', metadata={'Authors': 'A. Ghafarollahi, M. J. Buehler', 'Published': '2024-01-27', 'Summary': 'Designing de novo proteins beyond those found in nature holds significant\\npromise for advancements in both scientific and engineering applications.\\nCurrent methodologies for protein design often rely on AI-based models, such as\\nsurrogate models that address end-to-end problems by linking protein structure\\nto material properties or vice versa. However, these models frequently focus on\\nspecific material objectives or structural properties, limiting their\\nflexibility when incorporating out-of-domain knowledge into the design process\\nor comprehensive data analysis is required. In this study, we introduce\\nProtAgents, a platform for de novo protein design based on Large Language\\nModels (LLMs), where multiple AI agents with distinct capabilities\\ncollaboratively address complex tasks within a dynamic environment. The\\nversatility in agent development allows for expertise in diverse domains,\\nincluding knowledge retrieval, protein structure analysis, physics-based\\nsimulations, and results analysis. The dynamic collaboration between agents,\\nempowered by LLMs, provides a versatile approach to tackling protein design and\\nanalysis problems, as demonstrated through diverse examples in this study. The\\nproblems of interest encompass designing new proteins, analyzing protein\\nstructures and obtaining new first-principles data -- natural vibrational\\nfrequencies -- via physics simulations. The concerted effort of the system\\nallows for powerful automated and synergistic design of de novo proteins with\\ntargeted mechanical properties. The flexibility in designing the agents, on one\\nhand, and their capacity in autonomous collaboration through the dynamic\\nLLM-based multi-agent environment on the other hand, unleashes great potentials\\nof LLMs in addressing multi-objective materials problems and opens up new\\navenues for autonomous materials discovery and design.', 'Title': 'ProtAgents: Protein discovery via large language model multi-agent collaborations combining physics and machine learning'}), 0.05162611332375033), (Document(page_content='LRLYALDLGLKEVVLRR\\nVTPAPASQPGVYTVEDV\\nTVDLEALRKQELSPEEQA\\nRLEKIRAKYDEMLADPE\\nFQALLDEVLARARAA\\nâ€™Hâ€™: 57.499999999, â€™Bâ€™: 0.0,\\nâ€™Eâ€™:\\n13.3333333333,\\nâ€™Gâ€™:\\n0.0,\\nâ€™Iâ€™:\\n4.1666666666,\\nâ€™Tâ€™:\\n8.3333333333,\\nâ€™Sâ€™:\\n3.33333333333,\\nâ€™Pâ€™:\\n6.6666666666,\\nâ€™-â€™:\\n6.6666666666\\n[0.7546,\\n1.0836,\\n1.5026,\\n1.8874,\\n2.0844,\\n2.3192,\\n2.7975,\\n3.0199,\\n3.0669,\\n3.1382]\\nâ€™Hâ€™:\\n61.666666666,\\nâ€™Bâ€™:\\n0.0, â€™Eâ€™: 15.0, â€™Gâ€™: 0.0, â€™Iâ€™:\\n0.0,\\nâ€™Tâ€™:\\n8.3333333333,\\nâ€™Sâ€™:\\n3.33333333333,\\nâ€™Pâ€™:\\n1.66666666666, â€™-â€™: 10.0\\n[0.5256,\\n1.0278,\\n1.1566,\\n1.2877,\\n1.5521,\\n1.9111,\\n2.1887,\\n2.4664,\\n2.734,\\n2.8731]\\nFigure 4: Overview of the multi-agent work to solve the complex task posed in experiment III, Section 2.3.\\nFirst the multi-agent uses Chroma to generate de novo protein sequences and structures conditioned on the input\\nCATH class. Then using the generated protein structures, the natural frequencies and secondary structures content are\\ncomputed. Next, the force (maximum force along the unfolding force-extension curve) and energy (the area under the', metadata={'Authors': 'A. Ghafarollahi, M. J. Buehler', 'Published': '2024-01-27', 'Summary': 'Designing de novo proteins beyond those found in nature holds significant\\npromise for advancements in both scientific and engineering applications.\\nCurrent methodologies for protein design often rely on AI-based models, such as\\nsurrogate models that address end-to-end problems by linking protein structure\\nto material properties or vice versa. However, these models frequently focus on\\nspecific material objectives or structural properties, limiting their\\nflexibility when incorporating out-of-domain knowledge into the design process\\nor comprehensive data analysis is required. In this study, we introduce\\nProtAgents, a platform for de novo protein design based on Large Language\\nModels (LLMs), where multiple AI agents with distinct capabilities\\ncollaboratively address complex tasks within a dynamic environment. The\\nversatility in agent development allows for expertise in diverse domains,\\nincluding knowledge retrieval, protein structure analysis, physics-based\\nsimulations, and results analysis. The dynamic collaboration between agents,\\nempowered by LLMs, provides a versatile approach to tackling protein design and\\nanalysis problems, as demonstrated through diverse examples in this study. The\\nproblems of interest encompass designing new proteins, analyzing protein\\nstructures and obtaining new first-principles data -- natural vibrational\\nfrequencies -- via physics simulations. The concerted effort of the system\\nallows for powerful automated and synergistic design of de novo proteins with\\ntargeted mechanical properties. The flexibility in designing the agents, on one\\nhand, and their capacity in autonomous collaboration through the dynamic\\nLLM-based multi-agent environment on the other hand, unleashes great potentials\\nof LLMs in addressing multi-objective materials problems and opens up new\\navenues for autonomous materials discovery and design.', 'Title': 'ProtAgents: Protein discovery via large language model multi-agent collaborations combining physics and machine learning'}), 0.01194620414989589), (Document(page_content='rule, i.e., the criterion used to select a variable for branching, has been identified as having a critical\\nimpact on performance [2]. Computational studies have served to identify a number of metrics\\nthat are good indicators of how a variable will perform. Notably, state-of-the-art branching rules\\nlook at the change in objective value in the resulting children nodes. More specifically, let zLPi\\nbe the objective value of the current node i and let zLPi+ and zLPiâˆ’ be the objective values of the\\ntwo nodes resulting from branching on candidate variable xk. This variable will be scored using a\\ncombination7 of âˆ†+ := zLPi+ âˆ’ zLPi and âˆ†âˆ’ := zLPiâˆ’ âˆ’ zLPi. These values can be explicitly\\ncalculated for each candidate at the moment of branching (thus solving two LPs per candidate).\\nSuch strategy, known as strong branching, was introduced in the context of the travelling salesman\\nproblem [7] and later standardised by CPLEX.', metadata={'Authors': 'Lara Scavuzzo, Karen Aardal, Andrea Lodi, Neil Yorke-Smith', 'Published': '2024-02-08', 'Summary': 'Mixed Integer Linear Programming (MILP) is a pillar of mathematical\\noptimization that offers a powerful modeling language for a wide range of\\napplications. During the past decades, enormous algorithmic progress has been\\nmade in solving MILPs, and many commercial and academic software packages\\nexist. Nevertheless, the availability of data, both from problem instances and\\nfrom solvers, and the desire to solve new problems and larger (real-life)\\ninstances, trigger the need for continuing algorithmic development. MILP\\nsolvers use branch and bound as their main component. In recent years, there\\nhas been an explosive development in the use of machine learning algorithms for\\nenhancing all main tasks involved in the branch-and-bound algorithm, such as\\nprimal heuristics, branching, cutting planes, node selection and solver\\nconfiguration decisions. This paper presents a survey of such approaches,\\naddressing the vision of integration of machine learning and mathematical\\noptimization as complementary technologies, and how this integration can\\nbenefit MILP solving. In particular, we give detailed attention to machine\\nlearning algorithms that automatically optimize some metric of branch-and-bound\\nefficiency. We also address how to represent MILPs in the context of applying\\nlearning algorithms, MILP benchmarks and software.', 'Title': 'Machine Learning Augmented Branch and Bound for Mixed Integer Linear Programming'}), -0.053560366560767125), (Document(page_content='Dividing (20) by (21) leads to\\nL\\n\\x10(aanti\\nm )âˆ’1 âˆ’ Î»n\\nÎ»n + Âµn\\n\\x11âˆ’1/2\\ntan\\n\\x10s\\n(aanti\\nm )âˆ’1 âˆ’ Î»n\\nÎ»n + Âµn\\nL\\n\\x11\\n= L(1 + Âµ\\nÎ»n\\n) tanh(L).\\nThe equation tan(x)/x = ËœC, where ËœC is constant, has exactly one solution in any interval [Ï€(k âˆ’\\n1/2), Ï€(k + 1/2)] for k âˆˆ Z. Therefore, there is only one admissible value of\\nq\\n(aanti\\nm\\n)âˆ’1âˆ’Î»n\\nÎ»n+Âµn\\nin\\neach of these interval. So,\\nÎ»n + (Î»n + Âµn)(m âˆ’ 1/2)2Ï€2/L2 â©½ (aanti\\nm )âˆ’1 â©½ Î»n + (Î»n + Âµn)(m + 1/2)2Ï€2/L2.\\n51\\nDOUM`ECHE BACH BIAU BOYER\\nStep 5: Conclusion.\\nRecall that the sequence (am)mâˆˆN is a non-increasing re-indexing of the\\nsequences (asym\\nm )mâˆˆN and (aanti\\nm )mâˆˆN. Putting the bounds obtained for asym\\nm\\nand aanti\\nm\\ntogether, we\\nobtain\\nÎ»n + (Î»n + Âµn)(m/2 âˆ’ 1)2Ï€2/L2 â©½ aâˆ’1\\nm â©½ Î»n + (Î»n + Âµn)(m/2 + 1)2Ï€2/L2,\\nand\\n(Î»n + Âµn)(m âˆ’ 2)2Ï€2/(4L2) â©½ aâˆ’1\\nm â©½ (Î»n + Âµn)(m + 4)2Ï€2/(4L2).\\nWe conclude that\\n4L2\\n(Î»n + Âµn)(m + 4)2Ï€2 â©½ am â©½\\n4L2\\n(Î»n + Âµn)(m âˆ’ 2)2Ï€2 .\\nF.4. Proof of Proposition 5.3', metadata={'Authors': 'Nathan DoumÃ¨che, Francis Bach, Claire Boyer, GÃ©rard Biau', 'Published': '2024-02-12', 'Summary': 'Physics-informed machine learning combines the expressiveness of data-based\\napproaches with the interpretability of physical models. In this context, we\\nconsider a general regression problem where the empirical risk is regularized\\nby a partial differential equation that quantifies the physical inconsistency.\\nWe prove that for linear differential priors, the problem can be formulated as\\na kernel regression task. Taking advantage of kernel theory, we derive\\nconvergence rates for the minimizer of the regularized risk and show that it\\nconverges at least at the Sobolev minimax rate. However, faster rates can be\\nachieved, depending on the physical error. This principle is illustrated with a\\none-dimensional example, supporting the claim that regularizing the empirical\\nrisk with physical information can be beneficial to the statistical performance\\nof estimators.', 'Title': 'Physics-informed machine learning as a kernel method'}), -0.08160909424476714)]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This context does not mention anything about Cart Pole in figure 2, so I cannot answer this question from the provided context.\n",
      "What are the three steps of the aggregated neural network in figure 2?\n",
      "Based on this content: these models belong to the family of message passing GNNs [5]. These models employ a mes-\n",
      "sage passing (or neighborhood aggregation) procedure to aggregate local information of nodes.\n",
      "Suppose each node is annotated with a feature vector, and let h(0)\n",
      "v\n",
      "âˆˆ Rd denote node vâ€™s initial\n",
      "feature vector. Then, GNNs iteratively update node representations as follows:\n",
      "m(k)\n",
      "v\n",
      "= AGGREGATE(k\n",
      "h(kâˆ’1)\n",
      "u\n",
      ": u âˆˆ N(v)\n",
      "\t\t\u0011\n",
      "h(k)\n",
      "v\n",
      "= COMBINE(k)\u0010\n",
      "h(kâˆ’1)\n",
      "v\n",
      ", m(k)\n",
      "v\n",
      "\u0011\n",
      "where N(v) denotes the set of neighbors of node v (in an undirected graphs), and AGGREGATE(k)\n",
      "is a permutation invariant function of the k-th layer that maps the feature vectors of the neigh-\n",
      "bors of a node v to a single aggregated vector. This aggregated vector is passed along with the\n",
      "previous representation of v\n",
      "Input node\n",
      "Neuron\n",
      "Output node\n",
      "...\n",
      "...\n",
      "Bias\n",
      "x1\n",
      "x2\n",
      "y\n",
      "Figure 1: Example of the graph representation of a 3-layer MLP which can process 2-dimensional\n",
      "input data.\n",
      "4\n",
      "Connection between MLPs and GNNs\n",
      "\n",
      "---\n",
      "\n",
      "x1\n",
      "x2\n",
      "1\n",
      "1\n",
      "1\n",
      "h11\n",
      "0\n",
      "h12\n",
      "h1n1\n",
      "h21\n",
      "h22\n",
      "h2n2\n",
      "...\n",
      "...\n",
      "x1\n",
      "x2\n",
      "1\n",
      "1\n",
      "1\n",
      "h11\n",
      "y\n",
      "h12\n",
      "h1n1\n",
      "h21\n",
      "h22\n",
      "h2n2\n",
      "k = 0\n",
      "k = 1\n",
      "k = 2\n",
      "k = 3\n",
      "Figure 2: An illustration of the computation of a 3-layer MLP as an asynchronous message\n",
      "passing procedure.\n",
      "We use the notation GNNMLP to denote the GNN model that is defined in Equation (2).\n",
      "The AGGREGATE function of the GNNMLP model is defined as follows:\n",
      "h(k)\n",
      "v\n",
      "= f\n",
      "\u0012\n",
      "X\n",
      "uâˆˆN â†(v)\n",
      "Î±uv h(kâˆ’1)\n",
      "u\n",
      "\u0013\n",
      "(2)\n",
      "where f is an activation function and Î±uv âˆˆ R is a trainable parameter for the pair of nodes u\n",
      "and v. Therefore, the trainable parameters of the model correspond to the set Î¸ =\n",
      "\b\n",
      "Î±uv : (u, v) âˆˆ\n",
      "EMLP\n",
      "\t\n",
      ". The set Î¸ can be thought of as attention coefficients that allow each node to attend to\n",
      "its neighbors. Note that the GNNMLP model does not utilize any COMBINE function. Note\n",
      "also that h(0)\n",
      "v\n",
      "âˆˆ R for all v âˆˆ VMLP. Therefore, we also have that h(t)\n",
      "v\n",
      "âˆˆ R for all v âˆˆ V and for all\n",
      "t âˆˆ [K]. To compute the final node representations, an asynchronous message-passing scheme\n",
      "\n",
      "---\n",
      "\n",
      "hidden layers, and an output layer. The higher the number of hidden\n",
      "layers (or â€œdepthâ€), the more complex the ML architecture becomes\n",
      "(LeCun et al. 2015). This is the case of cecilia, which consists of\n",
      "three neural networks with 5-6 layers each. In general, deeper archi-\n",
      "tectures are more capable of recognising more intricate relationships\n",
      "in the data (Goodfellow et al. 2016).\n",
      "In addition to the choice of ML architecture, the learning capabili-\n",
      "ties of a NN are also shaped by the way its neurons are interconnected\n",
      "with one another. This connection is regulated by three parame-\n",
      "ters known as â€œweights,â€ â€œbiases,â€ and â€œactivation functions.â€ The\n",
      "weights and biases determine the importance of the neuronal connec-\n",
      "tions, while the activation functions employ non-linear operations to\n",
      "transform the input data of a set of neurons into useful output param-\n",
      "MNRAS 000, 1â€“28 (2024)\n",
      "Machine Learning Analysis of Polluted White Dwarfs\n",
      "3\n",
      "wn,1\n",
      "wn,2\n",
      "wn,3\n",
      "wn,M\n",
      "x1\n",
      "x2\n",
      "x3\n",
      "xM\n",
      "S\n",
      "ð‘”!\n",
      "yn\n",
      "Composition\n",
      "Function\n",
      "\n",
      "---\n",
      "\n",
      "During this process, the NN is exposed to labeled observations in\n",
      "order to identify hidden patterns in the data and learn to generate\n",
      "predictions that closely resemble the expected outcome for a given\n",
      "set of input parameters. As the training proceeds, the predictive\n",
      "accuracy of the NN is gradually improved with a technique known\n",
      "as â€œbackpropagation.â€ This technique calculates the loss function\n",
      "at each iteration to adjust the model parameters of the network. A\n",
      "standard formulation of the loss function is the quadratic expression\n",
      "Jð‘ž = 1\n",
      "2\n",
      "ð‘ƒ\n",
      "âˆ‘ï¸\n",
      "ð‘=1\n",
      "(ð‘¦ð‘ž,ð‘ âˆ’ Ë†ð‘¦ð‘ž,ð‘)2 = 1\n",
      "2\n",
      "ð‘ƒ\n",
      "âˆ‘ï¸\n",
      "ð‘=1\n",
      "ð‘’2\n",
      "ð‘ž,ð‘,\n",
      "(2)\n",
      "where ð‘ž is the index of a generic instance,2 ð‘ƒ is the total number\n",
      "of output neurons, ð‘ is the index of a generic output neuron, Ë†ð‘¦ð‘ž,ð‘\n",
      "is the prediction of the ð‘-th output neuron, ð‘¦ð‘ž,ð‘ is the known true\n",
      "output, and ð‘’ denotes the residual error difference between Ë†ð‘¦ and ð‘¦.\n",
      "For a given training dataset, the aggregated loss function of all the\n",
      "instances ð‘„ can then be expressed as\n",
      "J =\n",
      "ð‘„\n",
      "âˆ‘ï¸\n",
      "ð‘ž=1\n",
      "Jð‘ž.\n",
      "(3)\n",
      "\n",
      "---\n",
      "\n",
      "the neurons. \n",
      "Moreover, observing the differences with the original \n",
      "image during the process (shown in figure 16), it can be con- \n",
      "cluded that the neurons that get more affected by change the \n",
      "ones from the input layer of the DNN. Therefore, an analy- \n",
      "sis of the input neurons of the DNN has been carried out to \n",
      "observe their evolution in the process of an adversarial ex- \n",
      "ample acquisition. A total of 69381 test images4 were used \n",
      "to study which neurons participated significantly in the pre- \n",
      "diction for a particular image class. A neuron participates \n",
      "in the prediction of an image if the assigned value in the \n",
      " \n",
      "4 https://www.kaggle.com/paultimothymooney/breast- \n",
      "histopathology-images \n",
      "behavior visualization is non-zero. For this purpose, the par- \n",
      "ticipation of each neuron per class was calculated counting \n",
      "the number times a neuron participated, i.e., the number of \n",
      "times the activation value different from zero. This value ob- \n",
      "Neuron \n",
      "Class 0 frequency \n",
      "Class 1 frequency\n",
      "    answer this question: What are the three steps of the aggregated neural network in figure 2?\n",
      "1. AGGREGATE the feature vectors of the neighbors of a node v to a single aggregated vector.\n",
      "2. COMBINE the previous representation of v, and the aggregated vector.\n",
      "3. Compute the final node representations using an asynchronous message-passing scheme.\n",
      "What are the machine learning models used in predicting harmful algal bloom\n",
      "closures and aiding decision making in mussel farming?\n",
      "Based on this content: mussel production areas. Consequently, the classification of mussel production areas will focus on whether\n",
      "the presence of lipophilic toxin in mussel flesh exceeds the legal threshold or not. To do this, a comparison of\n",
      "3\n",
      "solutions will be carried out, applying different machine learning techniques to predict the state of production\n",
      "areas affected by DSP-type toxins. Taking into account previous studies carried out in the field ([15]), a\n",
      "total of 6 classification techniques were selected: Artificial Neural Network (ANN), Support Vector Machines\n",
      "(SVMs), k-Nearest Neighbour (kNN), XGBoost, Random Forest and NaÃ¯ve Bayes. This model can be used by\n",
      "government agencies with responsibilities in the control of shellfish production areas and its use can be of\n",
      "benefit to the mussel industry and the consumer. A workflow of the proposed system can be seen in figure 1.\n",
      "Figure 1: Schematic representation of the machine learning-based system for predicting harmful algal bloom\n",
      "\n",
      "---\n",
      "\n",
      "Machine Learning in management of precautionary\n",
      "closures caused by lipophilic biotoxins âˆ—\n",
      "Andres Molares-Ulloa, Enrique Fernandez-Blanco, Alejandro Pazos, Daniel Rivero\n",
      "Universidade da CoruÃ±a, Department of Computer Science and Information Technology,\n",
      "Faculty of Computer Science, 15071, A CoruÃ±a, Spain\n",
      "Centro de investigaciÃ³n CITIC, Department of Computer Science and Information Technology,\n",
      "University of A CoruÃ±a, 15071, A CoruÃ±a, Spain\n",
      "Biomedical Research Institute of A CoruÃ±a (INIBIC), University Hospital Complex of A Coruna (CHUAC),\n",
      "A Coruna, 15006, Spain\n",
      "andres.molares@udc.es\n",
      "Abstract\n",
      "Mussel farming is one of the most important aquaculture industries. The main risk to mussel\n",
      "farming is harmful algal blooms (HABs), which pose a risk to human consumption. In\n",
      "Galicia, the Spanish main producer of cultivated mussels, the opening and closing of the\n",
      "production areas is controlled by a monitoring program. In addition to the closures resulting\n",
      "\n",
      "---\n",
      "\n",
      "Hybrid Machine Learning techniques in the\n",
      "management of harmful algal blooms impact âˆ—\n",
      "Andres Molares-Ulloa, Daniel Rivero, Enrique Fernandez-Blanco\n",
      "Universidade da CoruÃ±a, Department of Computer Science and Information Technology,\n",
      "Faculty of Computer Science, 15071, A CoruÃ±a, Spain\n",
      "Centro de investigaciÃ³n CITIC, Department of Computer Science and Information Technology,\n",
      "University of A CoruÃ±a, 15071, A CoruÃ±a, Spain\n",
      "andres.molares@udc.es\n",
      "JesÃºs Gil Ruiz, Luis de-la-Fuente-ValentÃ­n\n",
      "Universidad Internacional de La Rioja. Avenida de la Paz, 137, 26006 LogroÃ±o, La Rioja, Spain,\n",
      "Escuela Superior de IngenierÃ­a y TecnologÃ­a\n",
      "Abstract\n",
      "Harmful algal blooms (HABs) are episodes of high concentrations of algae that are potentially\n",
      "toxic for human consumption. Mollusc farming can be affected by HABs because, as filter\n",
      "feeders, they can accumulate high concentrations of marine biotoxins in their tissues. To\n",
      "avoid the risk to human consumption, harvesting is prohibited when toxicity is detected. At\n",
      "\n",
      "---\n",
      "\n",
      "perspective, such as hybrid machine learning algorithms ([36]).\n",
      "The study has focused only on the Vigo estuary, as it is one of the most important Galician estuaries for the\n",
      "production of mussels, and because of its geomorphological characteristics that give it a behaviour in the\n",
      "distribution and evolution of algal blooms of great scientific interest. However, the study is continuing with\n",
      "the aim of supporting the rest of the Galician estuaries with mussel production.\n",
      "In this study, variables identified as relevant in the state of the art have been selected. However, other\n",
      "new variables (e.g. wind, currents, other toxic phytoplankton species, etc.) could be considered as input\n",
      "parameters in the training of machine learning algorithms.\n",
      "One of the limiting factors in conducting this study has been the amount of missing data from the time series\n",
      "used as data sets. It is therefore considered that the creation of a system capable of obtaining or generating\n",
      "\n",
      "---\n",
      "\n",
      "L. (2023). Hybrid machine learning techniques in the management of harmful algal blooms impact.\n",
      "Computers and Electronics in Agriculture, 211, 107988. DOI:10.1016/j.compag.2023.107988.\n",
      "arXiv:2402.09271v1  [cs.LG]  14 Feb 2024\n",
      "learning models like Neural-Network-Adding Bootstrap (BAGNET) and Discriminative\n",
      "Nearest Neighbor Classification (SVM-KNN) when estimating the state of production areas.\n",
      "The study has been carried out in several estuaries with different levels of complexity in\n",
      "the episodes of algal blooms to demonstrate the generalization capacity of the models in\n",
      "bloom detection. As a result, we could observe that, with an average recall value of 93.41%\n",
      "and without dropping below 90% in any of the estuaries, BAGNET outperforms the other\n",
      "models both in terms of results and robustness.\n",
      "Keywords Machine Learning Â· Harmful Algal Blooms Â· Biotoxins Â· Aquaculture Â· Hybrid Techniques\n",
      "1\n",
      "Introduction\n",
      "    answer this question: What are the machine learning models used in predicting harmful algal bloom\n",
      "closures and aiding decision making in mussel farming?\n",
      "The machine learning models used in predicting harmful algal bloom closures and aiding decision making in mussel farming include:\n",
      "- Artificial Neural Network (ANN)\n",
      "- Support Vector Machines (SVMs)\n",
      "- k-Nearest Neighbour (kNN)\n",
      "- XGBoost\n",
      "- Random Forest \n",
      "- NaÃ¯ve Bayes\n",
      "what is round-trip correctness (RTC) in terms of models evaluation?\n",
      "Based on this content: other: a forward model M : X â†’ Y and a backward model\n",
      "M âˆ’1 : Y â†’ X. These models could be a single LLM\n",
      "prompted differently.\n",
      "The central idea for unsupervised evaluation is the con-\n",
      "cept of round-trip correctness (RTC). Intuitively, for a\n",
      "â€œgoodâ€ forward and backward model we expect the output\n",
      "of Ë†x = M âˆ’1(M(x)) to be semantically equivalent to x. For\n",
      "example, as we discuss in Sec. 3, we can describe code with\n",
      "natural language in the forward pass and then generate back\n",
      "the code from the sampled natural language descriptions\n",
      "in the backward pass (Fig. 1). To compute RTC we need\n",
      "some function sim(x, Ë†x) that estimates the semantic equiva-\n",
      "lence between the original x and each predicted sample Ë†x.\n",
      "Such functions may include discrete or continuous metrics\n",
      "such as exact match, CodeBLEU (Ren et al., 2020), and\n",
      "CodeBERTScore (Zhou et al., 2023), and execution-based\n",
      "semantic equivalence oracles, such as unit test execution.\n",
      "We can then measure round-trip correctness as the ability of\n",
      "\n",
      "---\n",
      "\n",
      "The previous examples pertain to instances in which the RTC score is high. We now consider cases in which the RTC score\n",
      "is low. In Example #3, none of the sampled descriptions accurately reflect the edit, and consequently, they do not lead to the\n",
      "matching edit in the backward pass. While the underlying model is able to generate an edit which is consistent with the\n",
      "description for Sample #3, the descriptions for Sample #1 and Sample #2 are too confusing for the model such that it simply\n",
      "copies the old code without performing any edits. Despite the fact that these descriptions are inaccurate, the BLEU score\n",
      "(with respect to the PR comment) is relatively high, especially for Sample #1, again highlighting another instance in which\n",
      "RTC serves as a more reliable evaluation metric.\n",
      "In Example #4, we have an example in which the RTC score is 33.333. Of the three predicted descriptions, only one\n",
      "\n",
      "---\n",
      "\n",
      "the PR comment or baseline description. Examples have minor edits/re-format due to space constraints.\n",
      "the input and the prediction from the backward pass, and\n",
      "necessitates good predictions in both directions.\n",
      "6. Discussion & Conclusions\n",
      "In this work we used the concept of round-trip correctness\n",
      "for model evaluation and found that RTC strongly corre-\n",
      "lates with performance on narrow-domain human-curated\n",
      "benchmarks, measuring a similar quality of a modelâ€™s\n",
      "performance.\n",
      "RTC allows us to complement existing\n",
      "narrow-domain human-annotated benchmarks and measure\n",
      "an LLMâ€™s performance on a much wider spectrum of do-\n",
      "mains. RTC allows us to expand our evaluations into new\n",
      "tasks such as code and edit description, and code editing\n",
      "without requiring human annotations.\n",
      "We hope that this work motivates the community towards\n",
      "expanding the code evaluation benchmarks beyond narrow-\n",
      "domain ones. RTC seems to strike a balance between corre-\n",
      "lating with existing metrics and allowing to expand to new\n",
      "\n",
      "---\n",
      "\n",
      "similarity may yield arbitrary results. Second, the measure-\n",
      "ment of the performance of the forward and backward tasks\n",
      "is coupled: if M is unable to provide plausible samples, we\n",
      "cannot expect to measure the ability of the backward model\n",
      "M âˆ’1. This may be a problem if we care for only one of the\n",
      "forward or backward tasks.\n",
      "Finally, RTC assumes â€œreasonablyâ€ trained and instruction-\n",
      "tuned LLMs. In an adversarial setting, a forward model M\n",
      "can ignore the instruction and recite its input x. Then, the\n",
      "backward model M âˆ’1 can copy the output of the forward\n",
      "model M achieving perfect RTC. While this is unlikely\n",
      "to happen for models that employ common (pre)training\n",
      "methods, if we train/fine-tune models with the objective of\n",
      "Eq. 1 such a behavior may arise naturally.\n",
      "3. RTC for Code\n",
      "While RTC is general, it is well-suited for code where au-\n",
      "tomatically judging the semantic similarity (via sim(Â·)) is\n",
      "2\n",
      "Unsupervised Evaluation of Code LLMs with Round-Trip Correctness\n",
      "\n",
      "---\n",
      "\n",
      "Unsupervised Evaluation of Code LLMs with Round-Trip Correctness\n",
      "Miltiadis Allamanis * 1 Sheena Panthaplackel * 1 Pengcheng Yin * 1\n",
      "Abstract\n",
      "To evaluate code large language models (LLMs),\n",
      "research has relied on a few small manually cu-\n",
      "rated benchmarks, such as HumanEval and MBPP,\n",
      "which represent a narrow part of the real-world\n",
      "software domains. In this work, we introduce\n",
      "round-trip correctness (RTC) as an alternative\n",
      "evaluation method. RTC allows Code LLM eval-\n",
      "uation on a broader spectrum of real-world soft-\n",
      "ware domains without the need for costly human\n",
      "curation. RTC rests on the idea that we can ask a\n",
      "model to make a prediction (e.g., describe some\n",
      "code using natural language), feed that prediction\n",
      "back (e.g., synthesize code from the predicted de-\n",
      "scription), and check if this round-trip leads to\n",
      "code that is semantically equivalent to the origi-\n",
      "nal input. We show how to employ RTC to evalu-\n",
      "ate code synthesis and editing. We find that RTC\n",
      "    answer this question: what is round-trip correctness (RTC) in terms of models evaluation?\n",
      "Round-trip correctness (RTC) is a model evaluation method that assesses the quality of a model's predictions by checking if the output of a backward model is semantically equivalent to the original input.\n",
      "\n",
      "In the context of code evaluation, RTC can be used to evaluate code synthesis and editing tasks. For example, in code synthesis, a forward model can be used to generate a code snippet from a natural language description, and a backward model can be used to generate a natural language description from the generated code snippet. RTC can then be used to measure the ability of the forward and backward models to generate semantically equivalent code and natural language descriptions.\n",
      "What is the test accuracy of BlindTuner?\n",
      "Based on this content: sensitivity and kappa coefficient), as well as the number of features used to make the prediction. A smaller\n",
      "number of input variables would make it easier to make predictions, even on days when certain data are\n",
      "missing. Sensitivity is the most important factor to be taken into account due to the absolute priority of\n",
      "minimising false negatives (as they pose a risk to public health).\n",
      "2.4\n",
      "Experimentation setup\n",
      "By using the strategy of K-folds strategy, specifically 10-fold, yields 10 values of each statistic. The K-fold\n",
      "cross-validation procedure randomly divides a dataset into k disjoint blocks of approximately equal size, and\n",
      "each block is in turn used to test the model induced from the other k âˆ’ 1 blocks by a classification algorithm.\n",
      "The performance of the classification algorithm is evaluated by the average of the k-precisions resulting from\n",
      "the cross-validation of k-blocks. This method avoids choosing models with good averages but which perform\n",
      "11\n",
      "\n",
      "---\n",
      "\n",
      "ness. Every model has been evaluated through an extensive hyperparameter grid search. The results show the score \n",
      "for the hyperparameter configuration with the best mean value of the ten folds. \n",
      "Metrics. To evaluate the results obtained by each of the models, two different metrics have been used: F1-score \n",
      "(F1) and accuracy (acc) (Table 1). F1-score is a metric used to calculate the effectiveness of a classifier by taking \n",
      "into account its accuracy and recall values. F1 assumes that the two metrics used are equally important in calculating \n",
      "effectiveness. If one of them is more important, a different formula FÎ² would have to be used. The formula used to \n",
      "calculate this metric is as follows, where P equals the precision value and R equals the recall value. Accuracy refers \n",
      "to how close the result of a measurement is to the true value. In statistical terms, accuracy is related to the bias of an\n",
      "\n",
      "---\n",
      "\n",
      "0.9988\n",
      "0.9988\n",
      "0.9987\n",
      "0.6016\n",
      "0.60\n",
      "0.9988\n",
      "0.9988\n",
      "0.9988\n",
      "0.9988\n",
      "Negatives/Benign\n",
      "Errors (False Positives)\n",
      "283\n",
      "272\n",
      "439\n",
      "1635\n",
      "1642\n",
      "133\n",
      "283\n",
      "272\n",
      "133\n",
      "F1\n",
      "0.9991\n",
      "0.9991\n",
      "0.9991\n",
      "0.8311\n",
      "0.8306\n",
      "0.9992\n",
      "0.9991\n",
      "0.9991\n",
      "0.9992\n",
      "FPR\n",
      "0.0002\n",
      "0.0002\n",
      "0.0003\n",
      "0.0012\n",
      "0.0012\n",
      "0.0001\n",
      "0.0002\n",
      "0.0002\n",
      "0.0001\n",
      "Positives/Attacks\n",
      "Errors (False Negatives)\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "530382\n",
      "532505\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "F1\n",
      "0.9979\n",
      "0.9979\n",
      "0.9977\n",
      "0.0480\n",
      "0.0406\n",
      "0.9980\n",
      "0.9979\n",
      "0.9979\n",
      "0.9980\n",
      "FNR\n",
      "0.0037\n",
      "0.0037\n",
      "0.0037\n",
      "0.9753\n",
      "0.9792\n",
      "0.0037\n",
      "0.0037\n",
      "0.0037\n",
      "0.0037\n",
      "reached. The results were validated through a 5-fold\n",
      "cross-validation.\n",
      "3) Hyperparameters tuning: the SVM-RBF requires tuning\n",
      "of the hyperparameters Î³ and C, which must be chosen\n",
      "accurately. We optimized them through a 5-fold cross-\n",
      "validated grid search with\n",
      "â€¢ C = {0.1, 1, 5, 10, 102, 103, 104, 105}\n",
      "â€¢ Î³ = {0.01, 0.1, 0.5, 1}\n",
      "4) Model robustness: once the best model configuration\n",
      "has been found, 10-fold cross-validation has been used\n",
      "for calculating, for each fold, the performance metrics\n",
      "\n",
      "---\n",
      "\n",
      "Calculated according to Eq. 2 the accuracy estimates the correctness of a binary classification test that\n",
      "identifies or excludes a condition.\n",
      "Accuracy =\n",
      "TP + TN\n",
      "TP + FP + FN + TN\n",
      "(2)\n",
      "Due to the risk to the health of the population of introducing molluscs with toxins into the market, we have\n",
      "decided to prioritise a more conservative model in terms of opening production areas. This is reflected in the\n",
      "10\n",
      "system by the number of false negatives. A high recall (Eq. 3) is related to a lower value of false negatives.\n",
      "For this reason, recall is the reference metric in this study.\n",
      "Recall =\n",
      "TP\n",
      "TP + FN\n",
      "(3)\n",
      "The precision or positive predictive value (Eq. 4) denotes the variance of a set of values obtained from\n",
      "repeated measurements of a variable. The smaller the variance, the higher the precision. It is expressed as\n",
      "the ratio of the positive cases well classified by the model to the total number of positive predictions.\n",
      "Precision =\n",
      "TP\n",
      "TP + FP\n",
      "(4)\n",
      "\n",
      "---\n",
      "\n",
      "The F1-score (Eq. 5) is a widely used metric because it summarises recall and precision in a single metric.\n",
      "Therefore, it is a very useful metric for this study because of the inequality present in the data of closures\n",
      "versus openings.\n",
      "F1 = 2 Â· (Recall Â· Precision)\n",
      "(Recall + Precision)\n",
      "(5)\n",
      "Cohenâ€™s kappa coefficient, calculated according to Eq. 6, is a statistical measure that adjusts for the effect of\n",
      "chance on the proportion of observed agreement between two experts. In this equation, Pr(a) represents the\n",
      "observed relative agreement between observers, while Pr(e) is the hypothesised probability of agreement by\n",
      "chance.\n",
      "K = Pr(a) âˆ’ Pr(e)\n",
      "1 âˆ’ Pr(e)\n",
      "(6)\n",
      "Once calculated, it is analysed based on the scale of values proposed by Landis and Koch ([41]) (see table 3).\n",
      "Kappa statistic\n",
      "Magnitude of agreement\n",
      "<0.00\n",
      "No agreement\n",
      "0.00-0.20\n",
      "Slight\n",
      "0.21-0.40\n",
      "Fair\n",
      "0.41-0.60\n",
      "Moderate\n",
      "0.61-0.80\n",
      "Substantial\n",
      "0.81-1.00\n",
      "Almost perfect\n",
      "    answer this question: What is the test accuracy of BlindTuner?\n",
      "This document does not contain information about BlindTuner.\n",
      "What's the number of descriptors in Target Quantity - V in 1.3.5-triazine HBr?\n",
      "Based on this content: Volume model.\n",
      "One design guideline for determining\n",
      "5\n",
      "Added CSP Set\n",
      "Number of Descriptors\n",
      "Target Quantity - V\n",
      "Number of Descriptors\n",
      "Target Quantity - h\n",
      "Number of Descriptors\n",
      "Target Quantity - Phase\n",
      "None\n",
      "70\n",
      "122\n",
      "265\n",
      "1,3,5-triazine HBr\n",
      "63\n",
      "116\n",
      "268\n",
      "1,2,3-triazine HCl\n",
      "64\n",
      "109\n",
      "265\n",
      "1,2,4-triazine HCl\n",
      "65\n",
      "116\n",
      "274\n",
      "Pyridine HCl\n",
      "67\n",
      "110\n",
      "260\n",
      "Thiophene HCl\n",
      "63\n",
      "56\n",
      "265\n",
      "Piperidine HCl\n",
      "60\n",
      "45\n",
      "252\n",
      "TABLE I. Number of Descriptors used for each model. â€Added CSP setâ€ of â€Noneâ€ indicates that only the four CSP runs with 1,3,5-triazine\n",
      "HCl were included. For entries with a listed dataset under â€Added CSP setâ€, 10,000 structures from the added set were included in along with\n",
      "80% of the structures from the four 1,3,5-triazine CSP runs in fitting the decision tree regressor.\n",
      "Figure 3.\n",
      "Spearman correlation coefficients between target quanti-\n",
      "ties and Coulomb matrix and crystal graph singular value descriptors\n",
      "for the four datasets of 1,3,5-triazine HCl CSP. The orange curve\n",
      "\n",
      "---\n",
      "\n",
      "h for thiophene HCl, which takes 56 descriptors. For the other\n",
      "five h models, 110 to 122 descriptors are selected.\n",
      "The required number of descriptors can be rationalized by\n",
      "consideration of the Spearman correlation coefficients (Ï) be-\n",
      "tween the descriptors and target quantities, shown in Figure 3.\n",
      "The strongest correlations between descriptors and target val-\n",
      "ues are found for V DFT. Out of 506 possible descriptors, 380\n",
      "descriptors have |Ï| â‰¥ 0.8 with V DFT and only 6 descriptors\n",
      "have |Ï| â‰¤ 0.2. This indicates that the chosen descriptors are\n",
      "strongly correlated with V DFT. For h and phase, no descrip-\n",
      "tors with |Ï| â‰¥ 0.8 are present. Strong correlations between\n",
      "descriptor and target values allows the construction of low er-\n",
      "ror models with fewer fitting parameters. ML models con-\n",
      "structed for V DFT would be expected to require fewer descrip-\n",
      "tors than for hDFT and phase. Of the three target quantities, V\n",
      "has the most direct connection to the chosen descriptors. To\n",
      "\n",
      "---\n",
      "\n",
      "consist of four molecules of 1,3,5-triazine.\n",
      "S1(a), inclusion of the CGSV descriptors causes a minimal\n",
      "change in the MAEs of the volume model. For instance, at\n",
      "a maximum tree depth of 10 layers, without CGSV descrip-\n",
      "tors the model produces MAEs of 16.4 ËšA3 for the fitting set\n",
      "and 18.8 ËšA3 for the testing set. Inclusion of CGSV descrip-\n",
      "tors lowers the MAEs to 16.1 ËšA3 and 18.7 ËšA3 for the fitting\n",
      "and testing sets, respectively. In the case of the base model\n",
      "shown in Figure S1(b), the volume model without CGSV de-\n",
      "scriptors is found to have MAEs of 47.4 ËšA3 for the fitting set\n",
      "and 51.7 ËšA3 for the testing set. Inclusion of CGSV descriptors\n",
      "lowers the MAEs to 45.0 ËšA3 for the fitting set and 49.3 ËšA3 for\n",
      "the testing set. The 1,3,5-triazine model includes a limited re-\n",
      "gion of chemical space, only considering structures with four\n",
      "molecules of 1,3,5-triazine in the unit cell. The base model\n",
      "includes four different unit cell compositions with three ra-\n",
      "\n",
      "---\n",
      "\n",
      "found as the sorted eigenvalues of Ci j. Further descriptors\n",
      "are formed from: number of positive eigenvalues, number of\n",
      "negative eigenvalues, Tr(Ci j), and det(Ci j).\n",
      "We note that Tr(Ci j) = âˆ‘k Î»k = 1\n",
      "2 âˆ‘k Z2.4\n",
      "k\n",
      "where {Î»i} are the\n",
      "eigenvalues of the Coulomb matrix. The trace of the Coulomb\n",
      "matrix, then, provides a unique irrational number which char-\n",
      "acterizes the atomic composition of the unit cell. This allows\n",
      "the trace to be used as a categorical descriptor to identify the\n",
      "atomic contents of the cell. However, this trace descriptor\n",
      "only identifies the chemical contents of the cell, not the bond-\n",
      "ing arrangement. The descriptor formed from Tr(Cij) distin-\n",
      "guishes, e.g. 1,3,5-triazine (C3H3N3) from pyridine (C5H5N),\n",
      "but would not distinguish 1,3,5-triazine from 1,2,3-triazine.\n",
      "The crystal structure descriptors consist of the unit cell edge\n",
      "lengths A,B, and C and unit cell angles Î±, Î², Î³.\n",
      "While all molecules studied here are rigid and flat, the cho-\n",
      "\n",
      "---\n",
      "\n",
      "author upon reasonable request.\n",
      "15\n",
      "SUPPLEMENTAL MATERIALS\n",
      "S1.\n",
      "Choice of Molecular Crystals\n",
      "We focus on crystals formed from single ring heterocyclic\n",
      "organic molecules and HCl. The specific molecules are listed\n",
      "in Table S1 and shown in Figure 1. 1,3,5-triazine as the base\n",
      "constituent organic molecule is chosen because its small size\n",
      "lowers the computational cost of relaxing large number of\n",
      "crystals and allows for consideration of structures with mul-\n",
      "tiple molecules in the unit cell. Triazine is a component of\n",
      "many larger organic molecules[68, 69] used in industry for\n",
      "manufacturing resins [70] and dyes [71], and as an organic\n",
      "reagent [72]. Further, there are two other molecules, 1,2,3-\n",
      "triazine and 1,2,4-triazine, which differ from 1,3,5-triazine by\n",
      "only the arrangement of N and C atoms in the ring. We there-\n",
      "fore use 1,2,3-triazine and 1,2,4-triazine as model compounds\n",
      "to test the ability of the model to extrapolate.\n",
      "The ring of each organic molecule contains at least one het-\n",
      "    answer this question: What's the number of descriptors in Target Quantity - V in 1.3.5-triazine HBr?\n",
      "70\n",
      "What is the value of M, the number of  samples, selected in the experiments phase?\n",
      "Based on this content: NUMBER OF OBSERVATIONS\n",
      "M\n",
      "NUMBER OF OBSERVATIONS FOR EACH SAMPLE\n",
      "C\n",
      "THE NUMBER OF COMPONENTS THAT ARE CONTAINED IN THE SAMPLES\n",
      "L\n",
      "THE NUMBER OF INDUCING POINTS FOR EACH SAMPLE\n",
      "A\n",
      "THE NUMBER OF LATENT DIMENSIONS IN THE MO-GPLVM MODEL\n",
      "dij\n",
      "THE OBSERVATION FOR SAMPLE i AT POSITION j\n",
      "ric\n",
      "THE OBSERVED COMPONENT MIXTURE c FOR SAMPLE i\n",
      "sijc\n",
      "THE cTH PURE COMPONENT SPECTRA EVALUATED AT WAVELENGTH j FOR SAMPLE i\n",
      "xi\n",
      "THE LATENT VARIABLE OF THE iTH SAMPLE\n",
      "Î»j\n",
      "THE jTH LOCATION OF MEASUREMENT FOR ALL THE SAMPLES\n",
      "Ïµij\n",
      "THE GAUSSIAN NOISE OBSERVED FOR SAMPLE i AT POSITION j\n",
      "riÂ·\n",
      "THE RC VECTOR CONTAINING ALL OF THE MIXTURE COMPONENTS FOR SAMPLE i\n",
      "sijÂ·\n",
      "THE RC VECTOR CONTAINING ALL OF THE PURE COMPONENT VALUES FOR SAMPLE i AT POSITION j\n",
      "D\n",
      "THE RNÃ—M MATRIX THE TRAINING SPECTRA\n",
      "Dâˆ—\n",
      "THE RNâˆ—Ã—M MATRIX CONTAINING THE TEST SPECTRA\n",
      "D\n",
      "THE RNÃ—M MATRIX CONTAINING ALL OF THE OBSERVATIONS\n",
      "R\n",
      "THE RNÃ—C MATRIX CONTAINING THE TRAINING MIXTURE COMPONENTS\n",
      "Râˆ—\n",
      "THE RNÃ—C MATRIX CONTAINING THE TEST MIXTURE COMPONENTS\n",
      "R\n",
      "\n",
      "---\n",
      "\n",
      "Average value\n",
      "4.73\n",
      "4.83\n",
      "5.03\n",
      "4.86\n",
      "5.05\n",
      "Average value\n",
      "1.18\n",
      "0.97\n",
      "1.17\n",
      "2.57\n",
      "1.22\n",
      "Maximum value\n",
      "7.31\n",
      "9.11\n",
      "7.58\n",
      "8.02\n",
      "7.92\n",
      "Maximum value\n",
      "5.95\n",
      "5.12\n",
      "4.94\n",
      "11.67\n",
      "5.42\n",
      "Minimum value\n",
      "0.16\n",
      "0.07\n",
      "0.07\n",
      "0.08\n",
      "0.08\n",
      "Minimum value\n",
      "0.14\n",
      "0.05\n",
      "0.20\n",
      "0.03\n",
      "0.05\n",
      "Thermocline\n",
      "Phosphate\n",
      "stratification index\n",
      "dissolved (Âµmol âˆ— lâˆ’1)\n",
      "No. of sampling areas\n",
      "4\n",
      "10\n",
      "8\n",
      "11\n",
      "9\n",
      "No. of sampling areas\n",
      "4\n",
      "10\n",
      "8\n",
      "11\n",
      "9\n",
      "No. of samples\n",
      "1,258\n",
      "15,336\n",
      "2,076\n",
      "4,736\n",
      "7,812\n",
      "No. of samples\n",
      "1,524\n",
      "17,328\n",
      "2,428\n",
      "5,888\n",
      "8,952\n",
      "Average value\n",
      "0.59\n",
      "0.44\n",
      "0.73\n",
      "0.80\n",
      "0.64\n",
      "Average value\n",
      "0.37\n",
      "0.35\n",
      "0.32\n",
      "0.52\n",
      "0.41\n",
      "Maximum value\n",
      "4.44\n",
      "3.32\n",
      "3.03\n",
      "6.63\n",
      "4.32\n",
      "Maximum value\n",
      "1.22\n",
      "1.40\n",
      "1.01\n",
      "1.54\n",
      "1.43\n",
      "Minimum value\n",
      "0.00\n",
      "0.00\n",
      "0.01\n",
      "0.00\n",
      "0.00\n",
      "Minimum value\n",
      "0.06\n",
      "0.02\n",
      "0.04\n",
      "0.04\n",
      "0.03\n",
      "Halocline\n",
      "Nitrate\n",
      "stratification index\n",
      "dissolved (Âµmol âˆ— lâˆ’1)\n",
      "No. of sampling areas\n",
      "4\n",
      "10\n",
      "8\n",
      "11\n",
      "9\n",
      "No. of sampling areas\n",
      "4\n",
      "10\n",
      "8\n",
      "11\n",
      "9\n",
      "No. of samples\n",
      "1,222\n",
      "14,832\n",
      "2,012\n",
      "4,576\n",
      "7,560\n",
      "No. of samples\n",
      "1,524\n",
      "17,328\n",
      "2,428\n",
      "5,888\n",
      "8,952\n",
      "Average value\n",
      "0.71\n",
      "1.26\n",
      "1.12\n",
      "1.21\n",
      "0.49\n",
      "Average value\n",
      "3.88\n",
      "3.60\n",
      "3.80\n",
      "4.23\n",
      "3.82\n",
      "\n",
      "---\n",
      "\n",
      "Maximum value\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "Minimum value\n",
      "- 1.24\n",
      "- 1.35\n",
      "- 1.73\n",
      "- 4.91\n",
      "- 1.37\n",
      "Minimum value\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Chlorophyll-c\n",
      "State of\n",
      "concentration (mg âˆ— lâˆ’1)\n",
      "production areas\n",
      "No. of sampling areas\n",
      "4\n",
      "10\n",
      "8\n",
      "11\n",
      "9\n",
      "No. of sampling areas\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "No. of samples\n",
      "1,500\n",
      "17,184\n",
      "2,404\n",
      "5,768\n",
      "8,868\n",
      "No. of samples\n",
      "1,564\n",
      "18,768\n",
      "3,128\n",
      "6,256\n",
      "9,384\n",
      "Average value\n",
      "0.65\n",
      "0.77\n",
      "0.86\n",
      "0.63\n",
      "0.83\n",
      "Average value\n",
      "0.30\n",
      "0.17\n",
      "0.35\n",
      "0.50\n",
      "0.27\n",
      "Maximum value\n",
      "23.12\n",
      "7.70\n",
      "9.05\n",
      "11.73\n",
      "9.78\n",
      "Maximum value\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "Minimum value\n",
      "- 0.00\n",
      "0.01\n",
      "- 0.00\n",
      "0.00\n",
      "0.02\n",
      "Minimum value\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Dinophysis acuminata\n",
      "Average upwelling\n",
      "concentration (Cel âˆ— lâˆ’1)\n",
      "index (m3 âˆ— sâˆ’1 âˆ— kmâˆ’1)\n",
      "No. of sampling areas\n",
      "4\n",
      "10\n",
      "8\n",
      "11\n",
      "9\n",
      "No. of sampling areas\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "No. of samples\n",
      "1,526\n",
      "17,352\n",
      "2,432\n",
      "5,888\n",
      "8,952\n",
      "No. of samples\n",
      "1,548\n",
      "18,576\n",
      "3,096\n",
      "6,192\n",
      "9,288\n",
      "Average value\n",
      "217.98\n",
      "260.47\n",
      "236.45\n",
      "312.23\n",
      "283.65\n",
      "Average value\n",
      "50.59\n",
      "50.59\n",
      "50.59\n",
      "50.59\n",
      "50.59\n",
      "Maximum value\n",
      "8,280\n",
      "23,880\n",
      "8,720\n",
      "43,680\n",
      "12,040\n",
      "Maximum value\n",
      "2,575.74\n",
      "2,575.74\n",
      "2,575.74\n",
      "2,575.74\n",
      "2,575.74\n",
      "Minimum value\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "\n",
      "---\n",
      "\n",
      "Maximum value\n",
      "7.53\n",
      "15.01\n",
      "12.69\n",
      "30.67\n",
      "11.26\n",
      "Maximum value\n",
      "14.85\n",
      "18.36\n",
      "27.51\n",
      "38.12\n",
      "18.39\n",
      "Minimum value\n",
      "0.00\n",
      "0.00\n",
      "0.00\n",
      "0.00\n",
      "0.00\n",
      "Minimum value\n",
      "0.02\n",
      "0.00\n",
      "0.01\n",
      "0.00\n",
      "0.01\n",
      "Chlorophyll-a\n",
      "Nitrite\n",
      "concentration (mg âˆ— lâˆ’1)\n",
      "dissolved (Âµmol âˆ— lâˆ’1)\n",
      "No. of sampling areas\n",
      "4\n",
      "10\n",
      "8\n",
      "11\n",
      "9\n",
      "No. of sampling areas\n",
      "4\n",
      "10\n",
      "8\n",
      "11\n",
      "9\n",
      "No. of samples\n",
      "1,500\n",
      "17,184\n",
      "2,404\n",
      "5,768\n",
      "8,868\n",
      "No. of samples\n",
      "1,524\n",
      "17,328\n",
      "2,428\n",
      "5,888\n",
      "8,952\n",
      "Average value\n",
      "2.56\n",
      "2.98\n",
      "3.58\n",
      "2.80\n",
      "3.46\n",
      "Average value\n",
      "0.33\n",
      "0.31\n",
      "0.29\n",
      "0.41\n",
      "0.33\n",
      "Maximum value\n",
      "61.56\n",
      "23.32\n",
      "46.28\n",
      "24.96\n",
      "42.76\n",
      "Maximum value\n",
      "1.20\n",
      "1.44\n",
      "1.44\n",
      "2.03\n",
      "1.69\n",
      "Minimum value\n",
      "0.04\n",
      "0.04\n",
      "0.06\n",
      "0.02\n",
      "0.07\n",
      "Minimum value\n",
      "0.03\n",
      "0.01\n",
      "0.02\n",
      "0.01\n",
      "0.01\n",
      "Chlorophyll-b\n",
      "Production area\n",
      "concentration (mg âˆ— lâˆ’1)\n",
      "(One-hot-encoding)\n",
      "No. of sampling areas\n",
      "4\n",
      "10\n",
      "8\n",
      "11\n",
      "9\n",
      "No. of sampling areas\n",
      "2\n",
      "24\n",
      "4\n",
      "8\n",
      "12\n",
      "No. of samples\n",
      "1,500\n",
      "17,184\n",
      "2,404\n",
      "5,768\n",
      "8,868\n",
      "No. of samples\n",
      "1,566\n",
      "18,792\n",
      "3,132\n",
      "6,264\n",
      "9,396\n",
      "Average value\n",
      "0.00\n",
      "- 0.03\n",
      "- 0.03\n",
      "- 0.13\n",
      "- 0.00\n",
      "Average value\n",
      "0.50\n",
      "0.04\n",
      "0.25\n",
      "0.13\n",
      "0.08\n",
      "Maximum value\n",
      "3.98\n",
      "0.70\n",
      "2.11\n",
      "0.69\n",
      "5.28\n",
      "\n",
      "---\n",
      "\n",
      "No. of samples\n",
      "1,308\n",
      "15,408\n",
      "2,096\n",
      "5,192\n",
      "7,896\n",
      "No. of samples\n",
      "1,526\n",
      "17,352\n",
      "2,432\n",
      "5,888\n",
      "8,952\n",
      "Average value\n",
      "14.66\n",
      "14.16\n",
      "14.59\n",
      "15.45\n",
      "14.73\n",
      "Average value\n",
      "5.71\n",
      "19.97\n",
      "12.83\n",
      "5.49\n",
      "19.73\n",
      "Maximum value\n",
      "19.34\n",
      "20.10\n",
      "20.00\n",
      "22.68\n",
      "20.18\n",
      "Maximum value\n",
      "400\n",
      "1,600\n",
      "760\n",
      "360\n",
      "1,440\n",
      "Minimum value\n",
      "10.63\n",
      "11.42\n",
      "11.37\n",
      "10.87\n",
      "11.34\n",
      "Minimum value\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Dinophysis spp.\n",
      "Average salinity\n",
      "concentration (Cel âˆ— lâˆ’1)\n",
      "No. of sampling areas\n",
      "4\n",
      "10\n",
      "8\n",
      "11\n",
      "9\n",
      "No. of sampling areas\n",
      "4\n",
      "10\n",
      "8\n",
      "11\n",
      "9\n",
      "No. of samples\n",
      "1,302\n",
      "14,856\n",
      "2,024\n",
      "5,032\n",
      "7,608\n",
      "No. of samples\n",
      "1,526\n",
      "17,352\n",
      "2,432\n",
      "5,888\n",
      "8,952\n",
      "Average value\n",
      "35.12\n",
      "34.98\n",
      "34.73\n",
      "34.13\n",
      "34.74\n",
      "Average value\n",
      "36.74\n",
      "5.81\n",
      "4.93\n",
      "4.24\n",
      "9.18\n",
      "Maximum value\n",
      "36.78\n",
      "36.34\n",
      "36.14\n",
      "36.04\n",
      "37.12\n",
      "Maximum value\n",
      "19,305\n",
      "200\n",
      "280\n",
      "440\n",
      "1,485\n",
      "Minimum value\n",
      "21.12\n",
      "22.46\n",
      "28.08\n",
      "12.51\n",
      "0.56\n",
      "Minimum value\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Average\n",
      "Ammonium\n",
      "oxygen (ml âˆ— lâˆ’1)\n",
      "dissolved (Âµmol âˆ— lâˆ’1)\n",
      "No. of sampling areas\n",
      "4\n",
      "10\n",
      "8\n",
      "11\n",
      "9\n",
      "No. of sampling areas\n",
      "4\n",
      "10\n",
      "8\n",
      "11\n",
      "9\n",
      "No. of samples\n",
      "970\n",
      "15,360\n",
      "2,088\n",
      "5,040\n",
      "7,872\n",
      "No. of samples\n",
      "1,524\n",
      "17,304\n",
      "2,428\n",
      "5,888\n",
      "8,952\n",
      "    answer this question: What is the value of M, the number of  samples, selected in the experiments phase?\n",
      "The provided text does not specify the value of M, the number of samples, selected in the experiments phase.\n"
     ]
    }
   ],
   "source": [
    "from query import query_chroma_with_gemini\n",
    "from create_langchain_database_chroma import process_articles, load_data\n",
    "from langchain_community.embeddings.sentence_transformer import (\n",
    "    SentenceTransformerEmbeddings,\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "#Choosing our embedding model\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "chunk_size=1000 #size of chunks\n",
    "chunk_overlap=0 #size of overlaps\n",
    "seperator='\\n'  #separator of chunks\n",
    "chroma_db_name='C:/Users/zaiss/OneDrive - Ecole Centrale Casablanca/Hackathon/chroma_articles' # directory to store database \n",
    "# function which read articles, chunks, embedding and store on a chroma database\n",
    "file_path = \"C:/Users/zaiss/OneDrive - Ecole Centrale Casablanca/Hackathon/Pipeline1/Lien_articles_Z.xlsx\"\n",
    "data=load_data(file_path)\n",
    "#errors = process_articles(data,seperator, chroma_db_name,chunk_size,chunk_overlap,embedding_function)\n",
    "# Maintenant, errors contient la liste des numÃ©ros d'articles qui n'ont pas pu Ãªtre traitÃ©s.\n",
    "#print(f\"An error occured while reading those articles: {errors}\")\n",
    "\n",
    "#### querying###\n",
    "for i, row in data.iterrows():\n",
    "    question=str(data[\"QUESTION\"][i])\n",
    "    print(question)\n",
    "    \n",
    "    response=query_chroma_with_gemini(question, embedding_function, chroma_db_name)\n",
    "    print(response) \n",
    "    data.loc[i,'RÃ©ponsesPipeline2']=str(response)\n",
    "# function which read articles, chunks, embedding and store on a chroma database\n",
    "# df_liens=load_data(file_path)\n",
    "# df_merged = pd.merge(df_liens, data[['Lien', 'num_article', 'RÃ©ponsesPipeline2']], on='Lien', how='left')\n",
    "# with pd.ExcelWriter(file_path, engine='openpyxl', mode='a') as writer:\n",
    "#     # Ã‰crire le dataframe fusionnÃ© dans une nouvelle feuille\n",
    "#     df_merged.to_excel(writer, sheet_name='Pipeline2', index=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function which read articles, chunks, embedding and store on a chroma database\n",
    "df_liens=load_data(file_path)\n",
    "df_merged = pd.merge(df_liens, data[['Lien', 'RÃ©ponsesPipeline2']], on='Lien', how='left')\n",
    "with pd.ExcelWriter(file_path, engine='openpyxl', mode='a') as writer:\n",
    "    # Ã‰crire le dataframe fusionnÃ© dans une nouvelle feuille\n",
    "    df_merged.to_excel(writer, sheet_name='Pipeline2-1000onchuks-top10---2', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[text: \"0.9988\"\n",
       "]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
